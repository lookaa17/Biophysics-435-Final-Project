{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BaseStacking_and_SASA_Predictive_Models",
      "provenance": [],
      "collapsed_sections": [
        "UiYhlTM7wdhx",
        "NQ3N-gSKwtuY",
        "mnNJ4Gpvw1aB",
        "Kqi08EFJw9P9",
        "YqVUKi6nxOZF",
        "mik1TdE5iguZ",
        "XFKFJNdZjMy7",
        "-oeVxpeFilEF",
        "aqWrDkBwNTEI",
        "aC8Kcf2MjkCD"
      ]
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZFiOMtiwRbv",
        "colab_type": "text"
      },
      "source": [
        "# Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzqVz0pwwQ-h",
        "colab_type": "text"
      },
      "source": [
        "# Part 1: Predicting Base-Stacking Interactions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiYhlTM7wdhx",
        "colab_type": "text"
      },
      "source": [
        "## Prep the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVxFkIwXwihz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get -qq install -y python-rdkit librdkit1 rdkit-data\n",
        "!pip install -q joblib pandas sklearn tensorflow pillow deepchem"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVancgOWwigV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "82c8acda-ed24-486f-dabb-eb39a31a86d7"
      },
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from time import time\n",
        "from scipy.stats import randint as sp_randint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import warnings\n",
        "import random\n",
        "\n",
        "import sklearn as sk\n",
        "import rdkit as rd\n",
        "import deepchem as dc\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "c = pd.read_csv('final_training.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W1220 03:31:22.923301 140210940082048 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ3N-gSKwtuY",
        "colab_type": "text"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YW9d18RwibH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global variable \n",
        "NUMBER_CHEMICAL_SHIFT_TYPE = 19\n",
        "\n",
        "def get_cs_all(cs_all, id = \"2KOC\"):\n",
        "  '''    \n",
        "    This function gets chemical shifts for a particular RNA. \n",
        "    Assumes each RNA has a unique id  \n",
        "  '''\n",
        "  return(cs_all[(cs_all.id == id)])\n",
        "\n",
        "def get_cs_residues(cs_i, resid, dummy = 0):\n",
        "  '''    \n",
        "    This function return an array containing the chemical shifts for a particular residues in an RNA.    \n",
        "  '''\n",
        "  cs_tmp = cs_i[(cs_i.resid == resid)].drop(['id', 'resid', 'resname', 'Unnamed: 0', 'base_pairing', 'orientation', 'sugar_puckering', 'pseudoknot', 'stacking'], axis=1)\n",
        "  info_tmp = cs_i[(cs_i.resid == resid)]\n",
        "  if (cs_tmp.shape[0] != 1):\n",
        "     return(dummy*np.ones(shape=(1, NUMBER_CHEMICAL_SHIFT_TYPE)))\n",
        "  else:\n",
        "     return(cs_tmp.values)\n",
        "    \n",
        "def get_resnames(cs_i, resid, dummy = \"UNK\"):\n",
        "  '''    \n",
        "    This function returns the residue name for specified residue (resid)\n",
        "  '''\n",
        "  cs_tmp = cs_i[(cs_i.resid == resid)]  \n",
        "  if (cs_tmp.shape[0] != 1):\n",
        "     return(dummy)\n",
        "  else:\n",
        "     return(cs_tmp['resname'].values[0])\n",
        "\n",
        "def get_cs_features(cs_i, resid, neighbors=1):\n",
        "  '''    \n",
        "  This function chemical shifts and resnames for residue (resid) and its neighbors        \n",
        "\n",
        "  '''\n",
        "  cs = []\n",
        "  resnames = []\n",
        "  for i in range(resid-neighbors, resid+neighbors+1):\n",
        "    cs.append(get_cs_residues(cs_i, i))\n",
        "    resnames.append(get_resnames(cs_i, i))\n",
        "  return(resnames, np.array(cs))\n",
        "\n",
        "def get_columns_names(neighbors = 3, chemical_shift_types = 19):\n",
        "  '''\n",
        "    \n",
        "    Helper function that writes out the required column names\n",
        "    \n",
        "  '''\n",
        "\n",
        "  columns = ['id', 'resname', 'resid', 'stacking']\n",
        "  for i in range(0, neighbors*chemical_shift_types):\n",
        "    columns.append(i)\n",
        "  return(columns)\n",
        "\n",
        "def write_out_resname(neighbors=1):\n",
        "  '''\n",
        "  \n",
        "    Helper function that writes out the column names associated resnames for a given residue and its neighbors\n",
        "    \n",
        "  '''  \n",
        "  colnames = []\n",
        "  for i in range(1-neighbors-1, neighbors+1):\n",
        "    if i < 0: \n",
        "      colnames.append('R%s'%i)\n",
        "    elif i > 0: \n",
        "      colnames.append('R+%s'%i)\n",
        "    else: \n",
        "      colnames.append('R')\n",
        "  return(colnames)    \n",
        "\n",
        "\n",
        "def get_cs_features_rna(cs, neighbors=1, retain = ['id', 'stacking', 'resid']):\n",
        "  '''    \n",
        "    This function generates the complete required data frame an RNA    \n",
        "  '''\n",
        "  all_features = []\n",
        "  all_resnames = []\n",
        "  for resid in cs['resid'].unique():\n",
        "    resnames, features = get_cs_features(cs, resid, neighbors)\n",
        "    all_features.append(features.flatten())\n",
        "    all_resnames.append(resnames)\n",
        "\n",
        "  all_resnames = pd.DataFrame(all_resnames, dtype='object', columns = write_out_resname(neighbors))\n",
        "  all_features = pd.DataFrame(all_features, dtype='object')\n",
        "  info = pd.DataFrame(cs[retain].values, dtype='object', columns = retain)\n",
        "  return(pd.concat([info, all_resnames, all_features], axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIF0TvGgwiYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cs_features_rna_all(cs, neighbors = 2):  \n",
        "  '''    \n",
        "    This [should] function generate a pandas dataframe containing training data for all RNAs\n",
        "    Each row in the data frame should contain the class and chemical shifts for given residue and neighbors in a given RNA.\n",
        "    Use the function above to write function\n",
        "  '''\n",
        "  \n",
        "  cs_new = pd.DataFrame()\n",
        "  for i in range(0,len(c.id.unique())):\n",
        "    csData = get_cs_features_rna(get_cs_all(cs, c.id.unique()[i]), neighbors)\n",
        "    cs_new = pd.concat([cs_new, csData], axis=0) \n",
        "  # End: your code\n",
        "  return(cs_new)\n",
        "\n",
        "def create_training_testing(cs, leave_out = '2KOC', target_name = 'stacking', neighbors = 2, drop_names = ['id', 'stacking', 'resid']):\n",
        "  '''    \n",
        "    This function creates a training and testing set using leave one out    \n",
        "  '''\n",
        "  \n",
        "  # drop extraneous data  \n",
        "  drop_names = drop_names + list(write_out_resname(neighbors))  \n",
        "  \n",
        "  # does not contain leave_out\n",
        "  train = cs[(cs.id != leave_out)]\n",
        "  trainX = train.drop(drop_names, axis=1)\n",
        "  trainy = train[target_name]\n",
        " \n",
        "  # only contains leave_out\n",
        "  test = cs[(cs.id == leave_out)]\n",
        "  testX = test.drop(drop_names, axis=1)\n",
        "  testy = test[target_name]\n",
        "  \n",
        "  # return training and testing data\n",
        "  return(trainX.values, trainy.values, testX.values, testy.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnNJ4Gpvw1aB",
        "colab_type": "text"
      },
      "source": [
        "## Set up data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHvAvDnbwiV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc6db614-1bbb-4ff3-a900-0a2966e8b061"
      },
      "source": [
        "NEIGHBORS = 1\n",
        "id = '1A60'\n",
        "\n",
        "cs_all = get_cs_features_rna_all(c, neighbors = NEIGHBORS)\n",
        "\n",
        "trainX, trainy, testX, testy = create_training_testing(cs_all, leave_out = id, neighbors = NEIGHBORS)\n",
        "print(\"[INFO]: created training and testing data structures\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO]: created training and testing data structures\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfcgUSfxwiTW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "635d9d94-2532-49ce-8bff-cef99b88846f"
      },
      "source": [
        "cs = c\n",
        "cs_all.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>stacking</th>\n",
              "      <th>resid</th>\n",
              "      <th>R-1</th>\n",
              "      <th>R</th>\n",
              "      <th>R+1</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1A60</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>UNK</td>\n",
              "      <td>GUA</td>\n",
              "      <td>GUA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>92.7</td>\n",
              "      <td>74.9</td>\n",
              "      <td>72</td>\n",
              "      <td>82.5</td>\n",
              "      <td>65.4</td>\n",
              "      <td>153.6</td>\n",
              "      <td>109.8</td>\n",
              "      <td>157</td>\n",
              "      <td>142.1</td>\n",
              "      <td>5.65</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.12</td>\n",
              "      <td>4.23</td>\n",
              "      <td>7.469</td>\n",
              "      <td>6.124</td>\n",
              "      <td>4.07</td>\n",
              "      <td>3.99</td>\n",
              "      <td>8.413</td>\n",
              "      <td>8.03</td>\n",
              "      <td>91.9</td>\n",
              "      <td>75.7</td>\n",
              "      <td>72.4</td>\n",
              "      <td>82.3</td>\n",
              "      <td>66.1</td>\n",
              "      <td>155.207</td>\n",
              "      <td>118.377</td>\n",
              "      <td>160.7</td>\n",
              "      <td>141.4</td>\n",
              "      <td>5.88</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.31</td>\n",
              "      <td>7.83</td>\n",
              "      <td>5.549</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.15</td>\n",
              "      <td>7.871</td>\n",
              "      <td>7.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1A60</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>GUA</td>\n",
              "      <td>GUA</td>\n",
              "      <td>GUA</td>\n",
              "      <td>92.7</td>\n",
              "      <td>74.9</td>\n",
              "      <td>72</td>\n",
              "      <td>82.5</td>\n",
              "      <td>65.4</td>\n",
              "      <td>153.6</td>\n",
              "      <td>109.8</td>\n",
              "      <td>157</td>\n",
              "      <td>142.1</td>\n",
              "      <td>5.65</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.12</td>\n",
              "      <td>4.23</td>\n",
              "      <td>7.469</td>\n",
              "      <td>6.124</td>\n",
              "      <td>4.07</td>\n",
              "      <td>3.99</td>\n",
              "      <td>8.413</td>\n",
              "      <td>8.03</td>\n",
              "      <td>91.9</td>\n",
              "      <td>75.7</td>\n",
              "      <td>72.4</td>\n",
              "      <td>82.3</td>\n",
              "      <td>66.1</td>\n",
              "      <td>155.207</td>\n",
              "      <td>118.377</td>\n",
              "      <td>160.7</td>\n",
              "      <td>141.4</td>\n",
              "      <td>5.88</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.31</td>\n",
              "      <td>7.83</td>\n",
              "      <td>5.549</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.15</td>\n",
              "      <td>7.871</td>\n",
              "      <td>7.49</td>\n",
              "      <td>92.2</td>\n",
              "      <td>76.1</td>\n",
              "      <td>72.3</td>\n",
              "      <td>84.7</td>\n",
              "      <td>66</td>\n",
              "      <td>154.079</td>\n",
              "      <td>120.289</td>\n",
              "      <td>160.7</td>\n",
              "      <td>141.2</td>\n",
              "      <td>5.77</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.09</td>\n",
              "      <td>4.19</td>\n",
              "      <td>7.776</td>\n",
              "      <td>5.651</td>\n",
              "      <td>4.1</td>\n",
              "      <td>4.08</td>\n",
              "      <td>7.904</td>\n",
              "      <td>7.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1A60</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>GUA</td>\n",
              "      <td>GUA</td>\n",
              "      <td>ADE</td>\n",
              "      <td>91.9</td>\n",
              "      <td>75.7</td>\n",
              "      <td>72.4</td>\n",
              "      <td>82.3</td>\n",
              "      <td>66.1</td>\n",
              "      <td>155.207</td>\n",
              "      <td>118.377</td>\n",
              "      <td>160.7</td>\n",
              "      <td>141.4</td>\n",
              "      <td>5.88</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.31</td>\n",
              "      <td>7.83</td>\n",
              "      <td>5.549</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.15</td>\n",
              "      <td>7.871</td>\n",
              "      <td>7.49</td>\n",
              "      <td>92.2</td>\n",
              "      <td>76.1</td>\n",
              "      <td>72.3</td>\n",
              "      <td>84.7</td>\n",
              "      <td>66</td>\n",
              "      <td>154.079</td>\n",
              "      <td>120.289</td>\n",
              "      <td>160.7</td>\n",
              "      <td>141.2</td>\n",
              "      <td>5.77</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.09</td>\n",
              "      <td>4.19</td>\n",
              "      <td>7.776</td>\n",
              "      <td>5.651</td>\n",
              "      <td>4.1</td>\n",
              "      <td>4.08</td>\n",
              "      <td>7.904</td>\n",
              "      <td>7.24</td>\n",
              "      <td>92.2</td>\n",
              "      <td>75</td>\n",
              "      <td>72</td>\n",
              "      <td>81.2</td>\n",
              "      <td>65.8</td>\n",
              "      <td>153.7</td>\n",
              "      <td>118.8</td>\n",
              "      <td>157.085</td>\n",
              "      <td>139.1</td>\n",
              "      <td>5.96</td>\n",
              "      <td>4.57</td>\n",
              "      <td>4.53</td>\n",
              "      <td>4.54</td>\n",
              "      <td>7.52</td>\n",
              "      <td>5.932</td>\n",
              "      <td>4.28</td>\n",
              "      <td>4.11</td>\n",
              "      <td>8.413</td>\n",
              "      <td>7.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1A60</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>GUA</td>\n",
              "      <td>ADE</td>\n",
              "      <td>GUA</td>\n",
              "      <td>92.2</td>\n",
              "      <td>76.1</td>\n",
              "      <td>72.3</td>\n",
              "      <td>84.7</td>\n",
              "      <td>66</td>\n",
              "      <td>154.079</td>\n",
              "      <td>120.289</td>\n",
              "      <td>160.7</td>\n",
              "      <td>141.2</td>\n",
              "      <td>5.77</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.09</td>\n",
              "      <td>4.19</td>\n",
              "      <td>7.776</td>\n",
              "      <td>5.651</td>\n",
              "      <td>4.1</td>\n",
              "      <td>4.08</td>\n",
              "      <td>7.904</td>\n",
              "      <td>7.24</td>\n",
              "      <td>92.2</td>\n",
              "      <td>75</td>\n",
              "      <td>72</td>\n",
              "      <td>81.2</td>\n",
              "      <td>65.8</td>\n",
              "      <td>153.7</td>\n",
              "      <td>118.8</td>\n",
              "      <td>157.085</td>\n",
              "      <td>139.1</td>\n",
              "      <td>5.96</td>\n",
              "      <td>4.57</td>\n",
              "      <td>4.53</td>\n",
              "      <td>4.54</td>\n",
              "      <td>7.52</td>\n",
              "      <td>5.932</td>\n",
              "      <td>4.28</td>\n",
              "      <td>4.11</td>\n",
              "      <td>8.413</td>\n",
              "      <td>7.68</td>\n",
              "      <td>92.2</td>\n",
              "      <td>74.8</td>\n",
              "      <td>71.8</td>\n",
              "      <td>85.7</td>\n",
              "      <td>65.4</td>\n",
              "      <td>155.07</td>\n",
              "      <td>118.2</td>\n",
              "      <td>161.165</td>\n",
              "      <td>136.1</td>\n",
              "      <td>5.63</td>\n",
              "      <td>4.43</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.18</td>\n",
              "      <td>7.793</td>\n",
              "      <td>5.988</td>\n",
              "      <td>4.18</td>\n",
              "      <td>4.07</td>\n",
              "      <td>8.522</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1A60</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>ADE</td>\n",
              "      <td>GUA</td>\n",
              "      <td>CYT</td>\n",
              "      <td>92.2</td>\n",
              "      <td>75</td>\n",
              "      <td>72</td>\n",
              "      <td>81.2</td>\n",
              "      <td>65.8</td>\n",
              "      <td>153.7</td>\n",
              "      <td>118.8</td>\n",
              "      <td>157.085</td>\n",
              "      <td>139.1</td>\n",
              "      <td>5.96</td>\n",
              "      <td>4.57</td>\n",
              "      <td>4.53</td>\n",
              "      <td>4.54</td>\n",
              "      <td>7.52</td>\n",
              "      <td>5.932</td>\n",
              "      <td>4.28</td>\n",
              "      <td>4.11</td>\n",
              "      <td>8.413</td>\n",
              "      <td>7.68</td>\n",
              "      <td>92.2</td>\n",
              "      <td>74.8</td>\n",
              "      <td>71.8</td>\n",
              "      <td>85.7</td>\n",
              "      <td>65.4</td>\n",
              "      <td>155.07</td>\n",
              "      <td>118.2</td>\n",
              "      <td>161.165</td>\n",
              "      <td>136.1</td>\n",
              "      <td>5.63</td>\n",
              "      <td>4.43</td>\n",
              "      <td>4.4</td>\n",
              "      <td>4.18</td>\n",
              "      <td>7.793</td>\n",
              "      <td>5.988</td>\n",
              "      <td>4.18</td>\n",
              "      <td>4.07</td>\n",
              "      <td>8.522</td>\n",
              "      <td>7</td>\n",
              "      <td>93.1</td>\n",
              "      <td>76</td>\n",
              "      <td>71.8</td>\n",
              "      <td>82.2</td>\n",
              "      <td>64</td>\n",
              "      <td>159.7</td>\n",
              "      <td>96.5</td>\n",
              "      <td>141.7</td>\n",
              "      <td>141.851</td>\n",
              "      <td>5.64</td>\n",
              "      <td>4.17</td>\n",
              "      <td>4.42</td>\n",
              "      <td>4.32</td>\n",
              "      <td>7.4</td>\n",
              "      <td>5.11</td>\n",
              "      <td>4.32</td>\n",
              "      <td>4.17</td>\n",
              "      <td>7.48</td>\n",
              "      <td>8.169</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id stacking resid  R-1    R  R+1  ...     51     52    53    54     55     56\n",
              "0  1A60        1     1  UNK  GUA  GUA  ...   7.83  5.549   4.2  4.15  7.871   7.49\n",
              "1  1A60        1     2  GUA  GUA  GUA  ...  7.776  5.651   4.1  4.08  7.904   7.24\n",
              "2  1A60        1     3  GUA  GUA  ADE  ...   7.52  5.932  4.28  4.11  8.413   7.68\n",
              "3  1A60        1     4  GUA  ADE  GUA  ...  7.793  5.988  4.18  4.07  8.522      7\n",
              "4  1A60        1     5  ADE  GUA  CYT  ...    7.4   5.11  4.32  4.17   7.48  8.169\n",
              "\n",
              "[5 rows x 63 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kqi08EFJw9P9",
        "colab_type": "text"
      },
      "source": [
        "## Train MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvdlxC6aw9wF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8dae732-8314-44ae-9229-08164ca3e76a"
      },
      "source": [
        "# setup scaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(trainX)\n",
        "\n",
        "# transform input\n",
        "trainX_scaled = scaler.transform(trainX)\n",
        "testX_scaled = scaler.transform(testX)\n",
        "print(\"[INFO]: scaled the features\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO]: scaled the features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVWdkBSiw9uB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build a classifier\n",
        "clf = MLPClassifier(max_iter=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZusufXMxEUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify parameters to choose from\n",
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(50,50,50,50), (50,50,50), (50,50), (50,)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "}\n",
        "\n",
        "from scipy.stats import randint as sp_randint\n",
        "from scipy.stats import expon as sp_expon\n",
        "\n",
        "min_size, max_size = 5, 100\n",
        "parameter_space_distribution = {\n",
        "    'hidden_layer_sizes': [(sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
        "    'alpha': sp_expon(scale=.01),\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "    'learning_rate_init': sp_expon(scale=.001),\n",
        "}\n",
        "\n",
        "parameter_set = {\n",
        "    'hidden_layer_sizes': [(50,50,50,50)],\n",
        "    'activation': ['tanh'],\n",
        "    'solver': ['adam'],\n",
        "    'alpha': [0.0001],\n",
        "    'learning_rate': ['constant'],\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W9UOrQHxEDD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "b3ddc69b-0b96-4b86-c0c8-a85e25ab0350"
      },
      "source": [
        "# Setup and run randomized search\n",
        "n_iter_search = 2\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=parameter_set, n_iter=n_iter_search, cv=3, verbose = 5)\n",
        "\n",
        "random_search.fit(trainX_scaled, np.int_(trainy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV] alpha=0.0001, learning_rate=constant, hidden_layer_sizes=(50, 50, 50, 50), activation=tanh, solver=adam \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  alpha=0.0001, learning_rate=constant, hidden_layer_sizes=(50, 50, 50, 50), activation=tanh, solver=adam, score=0.822596630327, total=   4.2s\n",
            "[CV] alpha=0.0001, learning_rate=constant, hidden_layer_sizes=(50, 50, 50, 50), activation=tanh, solver=adam \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  alpha=0.0001, learning_rate=constant, hidden_layer_sizes=(50, 50, 50, 50), activation=tanh, solver=adam, score=0.81746031746, total=   4.1s\n",
            "[CV] alpha=0.0001, learning_rate=constant, hidden_layer_sizes=(50, 50, 50, 50), activation=tanh, solver=adam \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    8.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  alpha=0.0001, learning_rate=constant, hidden_layer_sizes=(50, 50, 50, 50), activation=tanh, solver=adam, score=0.849056603774, total=   4.1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   12.4s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   12.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "          estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
              "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
              "          fit_params=None, iid='warn', n_iter=2, n_jobs=None,\n",
              "          param_distributions={'alpha': [0.0001], 'activation': ['tanh'], 'solver': ['adam'], 'learning_rate': ['constant'], 'hidden_layer_sizes': [(50, 50, 50, 50)]},\n",
              "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "          return_train_score='warn', scoring=None, verbose=5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYw8QmYqw9q1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "596b80b0-5891-48e0-a6de-0d205d67d8b5"
      },
      "source": [
        "# Explore best parameters\n",
        "# Best parameter set\n",
        "print('Best parameters found:\\n', random_search.best_params_)\n",
        "\n",
        "# All results\n",
        "means = random_search.cv_results_['mean_test_score']\n",
        "stds = random_search.cv_results_['std_test_score']\n",
        "for mean, std, params in zip(means, stds, random_search.cv_results_['params']):\n",
        "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Best parameters found:\\n', {'alpha': 0.0001, 'learning_rate': 'constant', 'hidden_layer_sizes': (50, 50, 50, 50), 'activation': 'tanh', 'solver': 'adam'})\n",
            "0.830 (+/-0.028) for {'alpha': 0.0001, 'learning_rate': 'constant', 'hidden_layer_sizes': (50, 50, 50, 50), 'activation': 'tanh', 'solver': 'adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfp5e1rjw9oR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "46cdaa9f-cbd2-4bf1-992f-93c73dd75388"
      },
      "source": [
        "# Make predictions on test set\n",
        "y_true, y_pred = np.int_(testy) , random_search.predict(testX_scaled)\n",
        "print('Results on the test set:')\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results on the test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.45      0.50        11\n",
            "           1       0.83      0.88      0.85        33\n",
            "\n",
            "   micro avg       0.77      0.77      0.77        44\n",
            "   macro avg       0.69      0.67      0.68        44\n",
            "weighted avg       0.76      0.77      0.76        44\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0HfL2G4wiQw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6865552d-ffbd-4212-ddd9-d431f0889d9f"
      },
      "source": [
        "# Confusion Matrix\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# F1 Score --- ONE NEIGHBOR\n",
        "f1_score_1 = f1_score(y_true, y_pred)\n",
        "print(\"f1 score for 1 neighbor:\", f1_score_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 5  6]\n",
            " [ 4 29]]\n",
            "('f1 score for 1 neighbor:', 0.8529411764705883)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqVUKi6nxOZF",
        "colab_type": "text"
      },
      "source": [
        "## Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPA_u31lwSS8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "ba88a26e-4a26-47ae-d934-69017f7ca1ee"
      },
      "source": [
        "trainy=trainy.astype('int')\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_numba2 = RandomForestClassifier(max_depth=10, random_state=0, verbose=2)\n",
        "model_numba2.fit(trainX_scaled, trainy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "building tree 1 of 10\n",
            "building tree 2 of 10\n",
            "building tree 3 of 10\n",
            "building tree 4 of 10\n",
            "building tree 5 of 10\n",
            "building tree 6 of 10\n",
            "building tree 7 of 10\n",
            "building tree 8 of 10\n",
            "building tree 9 of 10\n",
            "building tree 10 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
              "            oob_score=False, random_state=0, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02Fkst_qxR_V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "94b9ff43-919f-4ee4-f1c2-70d077431ce5"
      },
      "source": [
        "y_true, y_pred = np.int_(testy) , model_numba2.predict(testX_scaled)\n",
        "print('Results on the test set:')\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "f1_score_1 = f1_score(y_true, y_pred)\n",
        "print(\"f1 score for 1 neighbor:\", f1_score_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results on the test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.18      0.31        11\n",
            "           1       0.79      1.00      0.88        33\n",
            "\n",
            "   micro avg       0.80      0.80      0.80        44\n",
            "   macro avg       0.89      0.59      0.59        44\n",
            "weighted avg       0.84      0.80      0.74        44\n",
            "\n",
            "('f1 score for 1 neighbor:', 0.88)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb_5sIzmxXKU",
        "colab_type": "text"
      },
      "source": [
        "# Part 2: SASA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmNxiCp48_MH",
        "colab_type": "text"
      },
      "source": [
        "1. Deepchem Multitask Regressor\n",
        "2. Models for individual SASA tasks\n",
        "\n",
        "  i.   Random Forests\n",
        "\n",
        "  ii.   MLPs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mik1TdE5iguZ",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi-UyIGNVgOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get -qq install -y python-rdkit librdkit1 rdkit-data\n",
        "!pip install -q joblib pandas sklearn tensorflow pillow deepchem"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP-4MFdnVg3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import f1_score\n",
        "from time import time\n",
        "from scipy.stats import randint as sp_randint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import warnings\n",
        "import random\n",
        "\n",
        "import sklearn as sk\n",
        "import rdkit as rd\n",
        "import tensorflow as tf\n",
        "import deepchem as dc\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFKFJNdZjMy7",
        "colab_type": "text"
      },
      "source": [
        "## Deepchem Multitask Regressor Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oeVxpeFilEF",
        "colab_type": "text"
      },
      "source": [
        "### Loads and Preps the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GICf9inu1MXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loads csv with SASA data\n",
        "d = pd.read_csv('final_training_sasa_outputs.csv')\n",
        "d = d.rename(columns={\"id\": \"sasa_id\", \"resname\": \"sasa_resname\", \"resid\": \"sasa_resid\"})\n",
        "\n",
        "# loads csv with chemical shifts\n",
        "c = pd.read_csv('final_training.csv')\n",
        "\n",
        "# concatenates the two into single dataframe\n",
        "e = pd.concat([c, d], axis=1, sort=False)\n",
        "e['resid'] = e['sasa_resid'].astype(int)\n",
        "c = e"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqWrDkBwNTEI",
        "colab_type": "text"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22_2wPEEjU38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global variable \n",
        "NUMBER_CHEMICAL_SHIFT_TYPE = 19\n",
        "\n",
        "def get_cs_all(cs_all, id = \"2KOC\"):\n",
        "  '''    \n",
        "    This function gets chemical shifts for a particular RNA. \n",
        "    Assumes each RNA has a unique id  \n",
        "  '''\n",
        "  return(cs_all[(cs_all.id == id)])\n",
        "\n",
        "def get_cs_residues(cs_i, resid, dummy = 0):\n",
        "  '''    \n",
        "    This function return an array containing the chemical shifts for a particular residues in an RNA.    \n",
        "  '''\n",
        "  cs_tmp = cs_i[(cs_i.resid == resid)].drop(['id', 'resid', 'resname', 'Unnamed: 0', 'base_pairing', 'orientation', 'sugar_puckering', 'pseudoknot', 'stacking', 'sasa_id', 'sasa_resname', 'sasa_resid', 'sasa-All-atoms', 'sasa-Total-Side', 'sasa-Main-Chain', 'sasa-Non-polar', 'sasa-All-polar'], axis=1)\n",
        "  info_tmp = cs_i[(cs_i.resid == resid)]\n",
        "  if (cs_tmp.shape[0] != 1):\n",
        "     return(dummy*np.ones(shape=(1, NUMBER_CHEMICAL_SHIFT_TYPE)))\n",
        "  else:\n",
        "     return(cs_tmp.values)\n",
        "    \n",
        "def get_resnames(cs_i, resid, dummy = \"UNK\"):\n",
        "  '''    \n",
        "    This function returns the residue name for specified residue (resid)\n",
        "  '''\n",
        "  cs_tmp = cs_i[(cs_i.resid == resid)]  \n",
        "  if (cs_tmp.shape[0] != 1):\n",
        "     return(dummy)\n",
        "  else:\n",
        "     return(cs_tmp['resname'].values[0])\n",
        "\n",
        "def get_cs_features(cs_i, resid, neighbors=1):\n",
        "  '''    \n",
        "  This function chemical shifts and resnames for residue (resid) and its neighbors        \n",
        "\n",
        "  '''\n",
        "  cs = []\n",
        "  resnames = []\n",
        "  for i in range(resid-neighbors, resid+neighbors+1):\n",
        "    cs.append(get_cs_residues(cs_i, i))\n",
        "    resnames.append(get_resnames(cs_i, i))\n",
        "  return(resnames, np.array(cs))\n",
        "\n",
        "def get_columns_names(neighbors = 3, chemical_shift_types = 19):\n",
        "  '''\n",
        "    \n",
        "    Helper function that writes out the required column names\n",
        "    \n",
        "  '''\n",
        "\n",
        "  columns = ['id', 'resname', 'resid', 'sasa-All-atoms', 'sasa-Total-Side', 'sasa-Main-Chain', 'sasa-Non-polar', 'sasa-All-polar']\n",
        "  for i in range(0, neighbors*chemical_shift_types):\n",
        "    columns.append(i)\n",
        "  return(columns)\n",
        "\n",
        "def write_out_resname(neighbors=1):\n",
        "  '''\n",
        "  \n",
        "    Helper function that writes out the column names associated resnames for a given residue and its neighbors\n",
        "    \n",
        "  '''  \n",
        "  colnames = []\n",
        "  for i in range(1-neighbors-1, neighbors+1):\n",
        "    if i < 0: \n",
        "      colnames.append('R%s'%i)\n",
        "    elif i > 0: \n",
        "      colnames.append('R+%s'%i)\n",
        "    else: \n",
        "      colnames.append('R')\n",
        "  return(colnames)    \n",
        "\n",
        "\n",
        "def get_cs_features_rna(cs, neighbors=1, retain = ['id', 'sasa-All-atoms', 'sasa-Total-Side', 'sasa-Main-Chain', 'sasa-Non-polar', 'sasa-All-polar', 'resid']):\n",
        "  '''    \n",
        "    This function generates the complete required data frame an RNA    \n",
        "  '''\n",
        "  all_features = []\n",
        "  all_resnames = []\n",
        "  for resid in cs['resid'].unique():\n",
        "    resnames, features = get_cs_features(cs, resid, neighbors)\n",
        "    all_features.append(features.flatten())\n",
        "    all_resnames.append(resnames)\n",
        "\n",
        "  all_resnames = pd.DataFrame(all_resnames, dtype='object', columns = write_out_resname(neighbors))\n",
        "  all_features = pd.DataFrame(all_features, dtype='object')\n",
        "  info = pd.DataFrame(cs[retain].values, dtype='object', columns = retain)\n",
        "  return(pd.concat([info, all_resnames, all_features], axis=1))\n",
        "\n",
        "def get_cs_features_rna_all(cs, neighbors = 2):  \n",
        "  '''    \n",
        "    This [should] function generate a pandas dataframe containing training data for all RNAs\n",
        "    Each row in the data frame should contain the class and chemical shifts for given residue and neighbors in a given RNA.\n",
        "    Use the function above to write function\n",
        "  '''\n",
        "  \n",
        "  cs_new = pd.DataFrame()\n",
        "  for i in range(0,len(c.id.unique())):\n",
        "    csData = get_cs_features_rna(get_cs_all(cs, c.id.unique()[i]), neighbors)\n",
        "    cs_new = pd.concat([cs_new, csData], axis=0) \n",
        "  # End: your code\n",
        "  return(cs_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC8Kcf2MjkCD",
        "colab_type": "text"
      },
      "source": [
        "### Deepchem Dataset Generator functions\n",
        "\n",
        "(based on incomplete source code)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbBxKWOU2lB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pd_featurize(input_files, dataset_obj, data_dir=None, shard_size=8192):\n",
        "  \"\"\"Featurize provided files and write to specified location.\n",
        "  For large datasets, automatically shards into smaller chunks\n",
        "  for convenience.\n",
        "  Parameters\n",
        "  ----------\n",
        "  input_files: list\n",
        "    List of input filenames.\n",
        "  data_dir: str\n",
        "    (Optional) Directory to store featurized dataset.\n",
        "  shard_size: int\n",
        "    (Optional) Number of examples stored in each shard.\n",
        "  \"\"\"\n",
        "  import os\n",
        "  import gzip\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  import csv\n",
        "  import numbers\n",
        "  import tempfile\n",
        "  import time\n",
        "  import sys\n",
        "  import deepchem\n",
        "  from deepchem.utils.save import log\n",
        "  from deepchem.utils.save import load_csv_files\n",
        "  from deepchem.utils.save import load_sdf_files\n",
        "  from deepchem.utils.genomics import encode_fasta_sequence\n",
        "  from deepchem.feat import UserDefinedFeaturizer\n",
        "  from deepchem.data import DiskDataset, NumpyDataset, ImageDataset\n",
        "\n",
        "  log(\"Loading raw samples now.\", dataset_obj.verbose)\n",
        "  tasks = ['sasa-All-atoms', 'sasa-Total-Side', 'sasa-Main-Chain', 'sasa-Non-polar', 'sasa-All-polar'] #list of tasks\n",
        "\n",
        "  def featurize_data():\n",
        "    '''\n",
        "    New function that takes in the global input pandas dataframe and returns X, y, w, ids\n",
        "    numpy arrays to be fed into the deepchem dataset creator function.\n",
        "    '''\n",
        "    # copies the input pandas dataset\n",
        "    copyDataset = input_files\n",
        "    # creates a list of columns to be dropped (so that only chemical shifts fed to X)\n",
        "    drop_names = ['id', 'sasa-All-atoms', 'sasa-Total-Side', 'sasa-Main-Chain', 'sasa-Non-polar', 'sasa-All-polar', 'resid']\n",
        "    drop_names = drop_names = drop_names + list(write_out_resname(0))\n",
        "    # creates a list of columns for the model to predict values of\n",
        "    target_names = ['sasa-All-atoms', 'sasa-Total-Side', 'sasa-Main-Chain', 'sasa-Non-polar', 'sasa-All-polar']\n",
        "    # separates the X and y features for the dataset\n",
        "    X = copyDataset.drop(drop_names, axis=1)\n",
        "    y = copyDataset[target_names]\n",
        "    index = np.arange(19)\n",
        "    # converts the pandas dataframes to numpy arrays\n",
        "    X, idk = deepchem.data.data_loader.convert_df_to_numpy(X,index)\n",
        "    ids = np.arange(len(X))\n",
        "    y, w = deepchem.data.data_loader.convert_df_to_numpy(y,tasks)\n",
        "    # changes the NaN values in the numpy arrays into zeroes\n",
        "    X = np.nan_to_num(X)\n",
        "    y = np.nan_to_num(y)\n",
        "    \n",
        "    # returns the X, y, w, ids features for the dataset\n",
        "    yield X, y, w, ids\n",
        "\n",
        "\n",
        "  def shard_generator():\n",
        "    '''\n",
        "    Incomplete shard_generator function from featurize function in DataLoader class\n",
        "    from deepchem.data.data_loader source code.\n",
        "    Not used here.\n",
        "    '''\n",
        "    shard = input_files\n",
        "    time1 = time.time()\n",
        "    X, y = dataset_obj.featurize_data(shard)\n",
        "    ids = shard[dataset_obj.id_field].values\n",
        "    ids = ids[valid_inds]\n",
        "    if len(dataset_obj.tasks) > 0:\n",
        "      # Featurize task results iff they exist.\n",
        "      y, w = convert_df_to_numpy(shard, dataset_obj.tasks, dataset_obj.id_field)\n",
        "      # Filter out examples where featurization failed.\n",
        "      y, w = (y[valid_inds], w[valid_inds])\n",
        "      assert len(X) == len(ids) == len(y) == len(w)\n",
        "    else:\n",
        "      # For prospective data where results are unknown, it makes\n",
        "      # no sense to have y values or weights.\n",
        "      y, w = (None, None)\n",
        "      assert len(X) == len(ids)\n",
        "    time2 = time.time()\n",
        "    log(\n",
        "        \"TIMING: featurizing shard %d took %0.3f s\" %\n",
        "        (shard_num, time2 - time1), dataset_obj.verbose)\n",
        "    yield X, y, w, ids\n",
        "\n",
        "  # creates and returns a deepchem datset using the X, y, w and ids features returned\n",
        "  # from the above featurize_data function\n",
        "  return DiskDataset.create_dataset(\n",
        "      featurize_data(), data_dir, tasks, verbose=dataset_obj.verbose)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCA03BswaB6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pd_data_loader(data):\n",
        "  '''\n",
        "  Loads in data from a pandas dataframe into a deepchem dataset and separates\n",
        "  it into train, valid, and test datasets.\n",
        "  '''\n",
        "\n",
        "  import os\n",
        "  import logging\n",
        "  import deepchem\n",
        "  from deepchem.utils.save import log\n",
        "\n",
        "  # load all the RNA features as a pandas dataframe\n",
        "  cs_all = get_cs_features_rna_all(data, neighbors = 0)\n",
        "  \n",
        "  # loads the pandas dataframe into a deepchem dataset\n",
        "  tasks = ['sasa-All-atoms', 'sasa-Total-Side', 'sasa-Main-Chain', 'sasa-Non-polar', 'sasa-All-polar'] #list of tasks\n",
        "  loader = deepchem.data.data_loader.DataLoader(tasks)\n",
        "  dataset = pd_featurize(cs_all, loader)\n",
        "\n",
        "  print(\"[INFO]: created training and testing data structures\")\n",
        "\n",
        "  # split the data into train, valid, and test sets\n",
        "  splitters = {\n",
        "      'index': deepchem.splits.IndexSplitter(),\n",
        "      'random': deepchem.splits.RandomSplitter(),\n",
        "      'scaffold': deepchem.splits.ScaffoldSplitter(),\n",
        "      'stratified': deepchem.splits.SingletaskStratifiedSplitter()\n",
        "  }\n",
        "  split = 'random'\n",
        "  splitter = splitters[split]\n",
        "  log(\"About to split dataset with {} splitter.\".format(split))\n",
        "  train, valid, test = splitter.train_valid_test_split(dataset)\n",
        "\n",
        "  # transform the data\n",
        "  transformers = []\n",
        "\n",
        "  # return tasks, (train, valid, test sets), and transformer\n",
        "  return tasks, (train, valid, test), transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxkrZWy-jntg",
        "colab_type": "text"
      },
      "source": [
        "### Multitask Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoUSy6M0Nq3U",
        "colab_type": "text"
      },
      "source": [
        "Loads the data and trains a Multitask Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxM2eaE5jMVs",
        "colab_type": "code",
        "outputId": "cff1e2ca-afa3-4d36-b32b-c4638d6b26e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "# loads and splits the data\n",
        "tasks, datasets, transformers = pd_data_loader(c)\n",
        "train_dataset, valid_dataset, test_dataset = datasets\n",
        "\n",
        "# creates and trains a multitask regressor for predicting the 5 SASA tasks based on the 19 chemical shifts\n",
        "model = dc.models.MultitaskRegressor(n_tasks=5, n_features=19, layer_sizes=[1000, 1000, 500, 400, 300, 200, 100, 10], dropouts=.5)\n",
        "model.fit(train_dataset, nb_epoch=10)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading raw samples now.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W1220 03:35:04.920492 140210940082048 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/deepchem/models/tensorgraph/tensor_graph.py:715: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W1220 03:35:04.928037 140210940082048 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/deepchem/models/tensorgraph/layers.py:2464: The name tf.FIFOQueue is deprecated. Please use tf.queue.FIFOQueue instead.\n",
            "\n",
            "W1220 03:35:04.936079 140210940082048 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/deepchem/models/tensorgraph/layers.py:1216: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W1220 03:35:04.952599 140210940082048 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TIMING: dataset construction took 1.184 s\n",
            "Loading dataset from disk.\n",
            "[INFO]: created training and testing data structures\n",
            "About to split dataset with random splitter.\n",
            "TIMING: dataset construction took 0.031 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.013 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.012 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W1220 03:35:05.147907 140210940082048 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/deepchem/models/tensorgraph/tensor_graph.py:728: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W1220 03:35:05.168153 140210940082048 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/deepchem/models/tensorgraph/optimizers.py:76: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W1220 03:35:05.740736 140210940082048 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/deepchem/models/tensorgraph/tensor_graph.py:1013: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "W1220 03:35:05.741990 140210940082048 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/deepchem/models/tensorgraph/tensor_graph.py:1013: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W1220 03:35:05.748630 140210940082048 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/deepchem/models/tensorgraph/tensor_graph.py:739: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "W1220 03:35:05.918457 140210940082048 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/deepchem/models/tensorgraph/tensor_graph.py:749: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "531232.116625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXoFrmLnN0iT",
        "colab_type": "text"
      },
      "source": [
        "Metrics of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHXTSLi-keUI",
        "colab_type": "code",
        "outputId": "ef92f9a4-a7f0-451b-ba48-fc36652d3ab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# computes the Pearson R2 score for each of the SASA tasks for the train dataset and the test dataset\n",
        "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
        "print(\"Model Tasks: \", ['sasa-All-atoms', 'sasa-Total-Side', 'sasa-Main-Chain', 'sasa-Non-polar', 'sasa-All-polar'])\n",
        "print(model.evaluate(train_dataset, [metric], transformers))\n",
        "print(\"\")\n",
        "print(\"Model Tasks: \", ['sasa-All-atoms', 'sasa-Total-Side', 'sasa-Main-Chain', 'sasa-Non-polar', 'sasa-All-polar'])\n",
        "print(model.evaluate(test_dataset, [metric], transformers))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Model Tasks: ', ['sasa-All-atoms', 'sasa-Total-Side', 'sasa-Main-Chain', 'sasa-Non-polar', 'sasa-All-polar'])\n",
            "computed_metrics: [0.01609697823504552, 0.007637485210277998, 0.011541177070959432, 0.009949218532251584, 0.012528712596440738]\n",
            "{'pearson_r2_score': [0.01609697823504552, 0.007637485210277998, 0.011541177070959432, 0.009949218532251584, 0.012528712596440738]}\n",
            "\n",
            "('Model Tasks: ', ['sasa-All-atoms', 'sasa-Total-Side', 'sasa-Main-Chain', 'sasa-Non-polar', 'sasa-All-polar'])\n",
            "computed_metrics: [0.01548135698143717, 0.010973720438411612, 0.006431489508091624, 0.006779608397916491, 0.014029525890830662]\n",
            "{'pearson_r2_score': [0.01548135698143717, 0.010973720438411612, 0.006431489508091624, 0.006779608397916491, 0.014029525890830662]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tF1AvRw-Acf",
        "colab_type": "text"
      },
      "source": [
        "## Individual Tasks Approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uCK2Btu-WdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loads csv file with all data\n",
        "c = pd.read_csv('final_training_sasa.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuZFZ3AouVXd",
        "colab_type": "text"
      },
      "source": [
        "### SASA-ALL-ATOMS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6Peqgys-Gxn",
        "colab_type": "text"
      },
      "source": [
        "#### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r44VLHeQMqZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global variable \n",
        "NUMBER_CHEMICAL_SHIFT_TYPE = 19\n",
        "\n",
        "def get_cs_all(cs_all, id = \"2KOC\"):\n",
        "  '''    \n",
        "    This function gets chemical shifts for a particular RNA. \n",
        "    Assumes each RNA has a unique id  \n",
        "  '''\n",
        "  return(cs_all[(cs_all.id == id)])\n",
        "\n",
        "def get_cs_residues(cs_i, resid, dummy = 0):\n",
        "  '''    \n",
        "    This function return an array containing the chemical shifts for a particular residues in an RNA.    \n",
        "  '''\n",
        "  cs_tmp = cs_i[(cs_i.resid == resid)].drop(['id', 'resid', 'resname', 'sasa-All-atoms',\t'sasa-Total-Side'\t, 'sasa-Main-Chain'\t,'sasa-Non-polar',\t'sasa-All-polar'], axis=1)\n",
        "  info_tmp = cs_i[(cs_i.resid == resid)]\n",
        "  if (cs_tmp.shape[0] != 1):\n",
        "     return(dummy*np.ones(shape=(1, NUMBER_CHEMICAL_SHIFT_TYPE)))\n",
        "  else:\n",
        "     return(cs_tmp.values)\n",
        "    \n",
        "def get_resnames(cs_i, resid, dummy = \"UNK\"):\n",
        "  '''    \n",
        "    This function returns the residue name for specified residue (resid)\n",
        "  '''\n",
        "  cs_tmp = cs_i[(cs_i.resid == resid)]  \n",
        "  if (cs_tmp.shape[0] != 1):\n",
        "     return(dummy)\n",
        "  else:\n",
        "     return(cs_tmp['resname'].values[0])\n",
        "\n",
        "def get_cs_features(cs_i, resid, neighbors=1):\n",
        "  '''    \n",
        "  This function chemical shifts and resnames for residue (resid) and its neighbors        \n",
        "\n",
        "  '''\n",
        "  cs = []\n",
        "  resnames = []\n",
        "  for i in range(resid-neighbors, resid+neighbors+1):\n",
        "    cs.append(get_cs_residues(cs_i, i))\n",
        "    resnames.append(get_resnames(cs_i, i))\n",
        "  return(resnames, np.array(cs))\n",
        "\n",
        "def get_columns_names(neighbors = 3, chemical_shift_types = 19):\n",
        "  '''\n",
        "    \n",
        "    Helper function that writes out the required column names\n",
        "    \n",
        "  '''\n",
        "\n",
        "  columns = ['id', 'resname', 'resid', 'sasa-All-atoms']\n",
        "  for i in range(0, neighbors*chemical_shift_types):\n",
        "    columns.append(i)\n",
        "  return(columns)\n",
        "\n",
        "def write_out_resname(neighbors=1):\n",
        "  '''\n",
        "  \n",
        "    Helper function that writes out the column names associated resnames for a given residue and its neighbors\n",
        "    \n",
        "  '''  \n",
        "  colnames = []\n",
        "  for i in range(1-neighbors-1, neighbors+1):\n",
        "    if i < 0: \n",
        "      colnames.append('R%s'%i)\n",
        "    elif i > 0: \n",
        "      colnames.append('R+%s'%i)\n",
        "    else: \n",
        "      colnames.append('R')\n",
        "  return(colnames)    \n",
        "\n",
        "\n",
        "def get_cs_features_rna(cs, neighbors=1, retain = ['id', 'sasa-All-atoms', 'resid']):\n",
        "  '''    \n",
        "    This function generates the complete required data frame an RNA    \n",
        "  '''\n",
        "  all_features = []\n",
        "  all_resnames = []\n",
        "  for resid in cs['resid'].unique():\n",
        "    resnames, features = get_cs_features(cs, resid, neighbors)\n",
        "    all_features.append(features.flatten())\n",
        "    all_resnames.append(resnames)\n",
        "\n",
        "  all_resnames = pd.DataFrame(all_resnames, columns = write_out_resname(neighbors))\n",
        "  all_features = pd.DataFrame(all_features)\n",
        "  info = pd.DataFrame(cs[retain].values, columns = retain)\n",
        "  return(pd.concat([info, all_resnames, all_features], axis=1))\n",
        "\n",
        "def get_cs_features_rna_all(cs, neighbors = 2):  \n",
        "  '''    \n",
        "    This [should] function generate a pandas dataframe containing training data for all RNAs\n",
        "    Each row in the data frame should contain the class and chemical shifts for given residue and neighbors in a given RNA.\n",
        "    Use the function above to write function\n",
        "  '''\n",
        "  \n",
        "  cs_new = pd.DataFrame()\n",
        "  for i in range(0,len(c.id.unique())):\n",
        "    csData = get_cs_features_rna(get_cs_all(cs, c.id.unique()[i]), neighbors)\n",
        "    cs_new = pd.concat([cs_new, csData], axis=0) \n",
        "  # End: your code\n",
        "  return(cs_new)\n",
        "\n",
        "def create_training_testing(cs, leave_out = '2KOC', target_name = 'sasa-All-atoms', neighbors = 2, drop_names = ['id', 'sasa-All-atoms', 'resid']):\n",
        "  '''    \n",
        "    This function creates a training and testing set using leave one out    \n",
        "  '''\n",
        "  \n",
        "  # drop extraneous data  \n",
        "  drop_names = drop_names + list(write_out_resname(neighbors))  \n",
        "  \n",
        "  # does not contain leave_out\n",
        "  train = cs[(cs.id != leave_out)]\n",
        "  trainX = train.drop(drop_names, axis=1)\n",
        "  trainy = train[target_name]\n",
        " \n",
        "  # only contains leave_out\n",
        "  test = cs[(cs.id == leave_out)]\n",
        "  testX = test.drop(drop_names, axis=1)\n",
        "  testy = test[target_name]\n",
        "  \n",
        "  # return training and testing data\n",
        "  return(trainX.values, trainy.values, testX.values, testy.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcakFNGmwOVy",
        "colab_type": "code",
        "outputId": "2b741124-9d22-4cfa-b83b-4c58ef7c5189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "NEIGHBORS = 1\n",
        "id = '1A60' #NEED TO FIGURE OUT WHY THE ID MUST MATCH THAT ABOVE/WHY CAN'T SELECT ANY ID\n",
        "\n",
        "cs_all = get_cs_features_rna_all(c, neighbors = NEIGHBORS)\n",
        "\n",
        "trainX, trainy, testX, testy = create_training_testing(cs_all, leave_out = id, neighbors = NEIGHBORS)\n",
        "print(\"[INFO]: created training and testing data structures\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO]: created training and testing data structures\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWjMZpP25xfh",
        "colab_type": "code",
        "outputId": "3041c478-b28d-4442-fc22-da4ea7261a29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# setup scaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(trainX)\n",
        "\n",
        "# transform input\n",
        "trainX_scaled = scaler.transform(trainX)\n",
        "testX_scaled = scaler.transform(testX)\n",
        "print(\"[INFO]: scaled the features\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO]: scaled the features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfzdtTrI75lP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#trainX = np.nan_to_num(trainX)\n",
        "trainX_scaled = np.nan_to_num(trainX_scaled)\n",
        "#trainX_scaled = trainX_scaled[~np.isnan(trainX_scaled)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUZzDzR350E5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build a classifier\n",
        "clf = MLPRegressor(max_iter=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1hno7Qu54C9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify parameters to choose from\n",
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(50,50,50,50), (50,50,50), (50,50), (50,)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "}\n",
        "\n",
        "from scipy.stats import randint as sp_randint\n",
        "from scipy.stats import expon as sp_expon\n",
        "\n",
        "min_size, max_size = 5, 100\n",
        "parameter_space_distribution = {\n",
        "    'hidden_layer_sizes': [(sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
        "    'alpha': sp_expon(scale=.01),\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "    'learning_rate_init': sp_expon(scale=.001),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtK7Sh4p57F8",
        "colab_type": "code",
        "outputId": "7c62a002-16b0-4553-d7af-6847dfce0fe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "# Setup and run randomized search\n",
        "n_iter_search = 2\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=parameter_space_distribution, n_iter=n_iter_search, cv=3, verbose = 5)\n",
        "\n",
        "random_search.fit(trainX_scaled, np.int_(trainy))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "[CV] solver=sgd, activation=relu, hidden_layer_sizes=(25,), alpha=0.008189219988522624, learning_rate=adaptive, learning_rate_init=0.000657164273581347 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=sgd, activation=relu, hidden_layer_sizes=(25,), alpha=0.008189219988522624, learning_rate=adaptive, learning_rate_init=0.000657164273581347, score=0.253945466728, total=   0.6s\n",
            "[CV] solver=sgd, activation=relu, hidden_layer_sizes=(25,), alpha=0.008189219988522624, learning_rate=adaptive, learning_rate_init=0.000657164273581347 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=sgd, activation=relu, hidden_layer_sizes=(25,), alpha=0.008189219988522624, learning_rate=adaptive, learning_rate_init=0.000657164273581347, score=0.321195416391, total=   0.6s\n",
            "[CV] solver=sgd, activation=relu, hidden_layer_sizes=(25,), alpha=0.008189219988522624, learning_rate=adaptive, learning_rate_init=0.000657164273581347 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=sgd, activation=relu, hidden_layer_sizes=(25,), alpha=0.008189219988522624, learning_rate=adaptive, learning_rate_init=0.000657164273581347, score=0.341933547859, total=   0.6s\n",
            "[CV] solver=adam, activation=tanh, hidden_layer_sizes=(49, 20, 51, 12), alpha=0.0027539481910834095, learning_rate=adaptive, learning_rate_init=0.0007566979897006438 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=adam, activation=tanh, hidden_layer_sizes=(49, 20, 51, 12), alpha=0.0027539481910834095, learning_rate=adaptive, learning_rate_init=0.0007566979897006438, score=-19.0986675605, total=   3.1s\n",
            "[CV] solver=adam, activation=tanh, hidden_layer_sizes=(49, 20, 51, 12), alpha=0.0027539481910834095, learning_rate=adaptive, learning_rate_init=0.0007566979897006438 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    5.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=adam, activation=tanh, hidden_layer_sizes=(49, 20, 51, 12), alpha=0.0027539481910834095, learning_rate=adaptive, learning_rate_init=0.0007566979897006438, score=-17.5766529428, total=   3.0s\n",
            "[CV] solver=adam, activation=tanh, hidden_layer_sizes=(49, 20, 51, 12), alpha=0.0027539481910834095, learning_rate=adaptive, learning_rate_init=0.0007566979897006438 \n",
            "[CV]  solver=adam, activation=tanh, hidden_layer_sizes=(49, 20, 51, 12), alpha=0.0027539481910834095, learning_rate=adaptive, learning_rate_init=0.0007566979897006438, score=-25.4807340576, total=   3.1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   11.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
              "          estimator=MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
              "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
              "          fit_params=None, iid='warn', n_iter=2, n_jobs=None,\n",
              "          param_distributions={'solver': ['sgd', 'adam', 'lbfgs'], 'activation': ['tanh', 'relu'], 'hidden_layer_sizes': [(49, 20, 51, 12), (70, 58, 93), (43, 93), (25,)], 'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f84f5e65350>, 'learning_rate': ['constant', 'adaptive'], 'learning_rate_init': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f84efccfe50>},\n",
              "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "          return_train_score='warn', scoring=None, verbose=5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TGeEviI7GXk",
        "colab_type": "code",
        "outputId": "fc0f04f2-e9a6-4ada-82a2-499644e06a90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Explore best parameters\n",
        "# Best parameter set\n",
        "print('Best parameters found:\\n', random_search.best_params_)\n",
        "\n",
        "# All results\n",
        "means = random_search.cv_results_['mean_test_score']\n",
        "stds = random_search.cv_results_['std_test_score']\n",
        "for mean, std, params in zip(means, stds, random_search.cv_results_['params']):\n",
        "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Best parameters found:\\n', {'solver': 'sgd', 'activation': 'relu', 'hidden_layer_sizes': (25,), 'alpha': 0.008189219988522624, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000657164273581347})\n",
            "0.306 (+/-0.075) for {'solver': 'sgd', 'activation': 'relu', 'hidden_layer_sizes': (25,), 'alpha': 0.008189219988522624, 'learning_rate': 'adaptive', 'learning_rate_init': 0.000657164273581347}\n",
            "-20.719 (+/-6.848) for {'solver': 'adam', 'activation': 'tanh', 'hidden_layer_sizes': (49, 20, 51, 12), 'alpha': 0.0027539481910834095, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0007566979897006438}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EClmt4ZD7LwL",
        "colab_type": "code",
        "outputId": "e7c272b3-2187-4a08-adbb-7dac94eb70cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Make predictions on test set\n",
        "y_true, y_pred = np.int_(testy) , random_search.predict(testX_scaled)\n",
        "print('Results on the test set:')\n",
        "print(r2_score(y_true, y_pred))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results on the test set:\n",
            "0.062474026875103394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05JrwiasR5Qs",
        "colab_type": "text"
      },
      "source": [
        "#### Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0qnRkl_R4AW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "eb9d9f65-f041-484a-8bfc-4c4350f04877"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "trainy=trainy.astype('int')\n",
        "\n",
        "model = RandomForestRegressor(max_depth=10, random_state=0, verbose=2)\n",
        "model.fit(trainX_scaled, trainy)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "building tree 1 of 10\n",
            "building tree 2 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 3 of 10\n",
            "building tree 4 of 10\n",
            "building tree 5 of 10\n",
            "building tree 6 of 10\n",
            "building tree 7 of 10\n",
            "building tree 8 of 10\n",
            "building tree 9 of 10\n",
            "building tree 10 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
              "           oob_score=False, random_state=0, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLsDTlLXSEK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a2eefb90-540b-4ccc-fbac-08037221d307"
      },
      "source": [
        "print(\"R2 score for Random Forest:\")\n",
        "model.score(testX_scaled, testy)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2 score for Random Forest:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12815280590861233"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7RbUWnFJIg5",
        "colab_type": "text"
      },
      "source": [
        "### SASA-TOTAL-SIDE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFez3TNaN2PO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global variable \n",
        "NUMBER_CHEMICAL_SHIFT_TYPE = 19\n",
        "\n",
        "def get_cs_all(cs_all, id = \"2KOC\"):\n",
        "  '''    \n",
        "    This function gets chemical shifts for a particular RNA. \n",
        "    Assumes each RNA has a unique id  \n",
        "  '''\n",
        "  return(cs_all[(cs_all.id == id)])\n",
        "\n",
        "def get_cs_residues(cs_i, resid, dummy = 0):\n",
        "  '''    \n",
        "    This function return an array containing the chemical shifts for a particular residues in an RNA.    \n",
        "  '''\n",
        "  cs_tmp = cs_i[(cs_i.resid == resid)].drop(['id', 'resid', 'resname', 'sasa-All-atoms',\t'sasa-Total-Side'\t, 'sasa-Main-Chain'\t,'sasa-Non-polar',\t'sasa-All-polar'], axis=1)\n",
        "  info_tmp = cs_i[(cs_i.resid == resid)]\n",
        "  if (cs_tmp.shape[0] != 1):\n",
        "     return(dummy*np.ones(shape=(1, NUMBER_CHEMICAL_SHIFT_TYPE)))\n",
        "  else:\n",
        "     return(cs_tmp.values)\n",
        "    \n",
        "def get_resnames(cs_i, resid, dummy = \"UNK\"):\n",
        "  '''    \n",
        "    This function returns the residue name for specified residue (resid)\n",
        "  '''\n",
        "  cs_tmp = cs_i[(cs_i.resid == resid)]  \n",
        "  if (cs_tmp.shape[0] != 1):\n",
        "     return(dummy)\n",
        "  else:\n",
        "     return(cs_tmp['resname'].values[0])\n",
        "\n",
        "def get_cs_features(cs_i, resid, neighbors=1):\n",
        "  '''    \n",
        "  This function chemical shifts and resnames for residue (resid) and its neighbors        \n",
        "\n",
        "  '''\n",
        "  cs = []\n",
        "  resnames = []\n",
        "  for i in range(resid-neighbors, resid+neighbors+1):\n",
        "    cs.append(get_cs_residues(cs_i, i))\n",
        "    resnames.append(get_resnames(cs_i, i))\n",
        "  return(resnames, np.array(cs))\n",
        "\n",
        "def get_columns_names(neighbors = 3, chemical_shift_types = 19):\n",
        "  '''\n",
        "    \n",
        "    Helper function that writes out the required column names\n",
        "    \n",
        "  '''\n",
        "\n",
        "  columns = ['id', 'resname', 'resid', 'sasa-Total-Side']\n",
        "  for i in range(0, neighbors*chemical_shift_types):\n",
        "    columns.append(i)\n",
        "  return(columns)\n",
        "\n",
        "def write_out_resname(neighbors=1):\n",
        "  '''\n",
        "  \n",
        "    Helper function that writes out the column names associated resnames for a given residue and its neighbors\n",
        "    \n",
        "  '''  \n",
        "  colnames = []\n",
        "  for i in range(1-neighbors-1, neighbors+1):\n",
        "    if i < 0: \n",
        "      colnames.append('R%s'%i)\n",
        "    elif i > 0: \n",
        "      colnames.append('R+%s'%i)\n",
        "    else: \n",
        "      colnames.append('R')\n",
        "  return(colnames)    \n",
        "\n",
        "\n",
        "def get_cs_features_rna(cs, neighbors=1, retain = ['id', 'sasa-Total-Side', 'resid']):\n",
        "  '''    \n",
        "    This function generates the complete required data frame an RNA    \n",
        "  '''\n",
        "  all_features = []\n",
        "  all_resnames = []\n",
        "  for resid in cs['resid'].unique():\n",
        "    resnames, features = get_cs_features(cs, resid, neighbors)\n",
        "    all_features.append(features.flatten())\n",
        "    all_resnames.append(resnames)\n",
        "\n",
        "  all_resnames = pd.DataFrame(all_resnames, columns = write_out_resname(neighbors))\n",
        "  all_features = pd.DataFrame(all_features)\n",
        "  info = pd.DataFrame(cs[retain].values, columns = retain)\n",
        "  return(pd.concat([info, all_resnames, all_features], axis=1))\n",
        "\n",
        "def get_cs_features_rna_all(cs, neighbors = 2):  \n",
        "  '''    \n",
        "    This [should] function generate a pandas dataframe containing training data for all RNAs\n",
        "    Each row in the data frame should contain the class and chemical shifts for given residue and neighbors in a given RNA.\n",
        "    Use the function above to write function\n",
        "  '''\n",
        "  \n",
        "  cs_new = pd.DataFrame()\n",
        "  for i in range(0,len(c.id.unique())):\n",
        "    csData = get_cs_features_rna(get_cs_all(cs, c.id.unique()[i]), neighbors)\n",
        "    cs_new = pd.concat([cs_new, csData], axis=0) \n",
        "  # End: your code\n",
        "  return(cs_new)\n",
        "\n",
        "def create_training_testing(cs, leave_out = '2KOC', target_name = 'sasa-Total-Side', neighbors = 2, drop_names = ['id', 'sasa-Total-Side', 'resid']):\n",
        "  '''    \n",
        "    This function creates a training and testing set using leave one out    \n",
        "  '''\n",
        "  \n",
        "  # drop extraneous data  \n",
        "  drop_names = drop_names + list(write_out_resname(neighbors))  \n",
        "  \n",
        "  # does not contain leave_out\n",
        "  train = cs[(cs.id != leave_out)]\n",
        "  trainX = train.drop(drop_names, axis=1)\n",
        "  trainy = train[target_name]\n",
        " \n",
        "  # only contains leave_out\n",
        "  test = cs[(cs.id == leave_out)]\n",
        "  testX = test.drop(drop_names, axis=1)\n",
        "  testy = test[target_name]\n",
        "  \n",
        "  # return training and testing data\n",
        "  return(trainX.values, trainy.values, testX.values, testy.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn7cbJqXKElB",
        "colab_type": "code",
        "outputId": "f0bf7102-b7c6-4f78-b7f7-eb114efa2c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "NEIGHBORS = 1\n",
        "id = '1A60' #NEED TO FIGURE OUT WHY THE ID MUST MATCH THAT ABOVE/WHY CAN'T SELECT ANY ID\n",
        "\n",
        "cs_all = get_cs_features_rna_all(c, neighbors = NEIGHBORS)\n",
        "\n",
        "trainX, trainy, testX, testy = create_training_testing(cs_all, leave_out = id, neighbors = NEIGHBORS)\n",
        "print(\"[INFO]: created training and testing data structures\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO]: created training and testing data structures\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcernhMCKM1I",
        "colab_type": "code",
        "outputId": "8fd7dbc0-b9af-4344-c00c-b7878bf9c99f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# setup scaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(trainX)\n",
        "\n",
        "# transform input\n",
        "trainX_scaled = scaler.transform(trainX)\n",
        "testX_scaled = scaler.transform(testX)\n",
        "print(\"[INFO]: scaled the features\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO]: scaled the features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsXv4pBrKTn_",
        "colab_type": "code",
        "outputId": "3de384d3-b173-4659-ddc5-593f757b3c7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "trainX_scaled = np.nan_to_num(trainX_scaled)\n",
        "\n",
        "# build a classifier\n",
        "clf = MLPRegressor(max_iter=1000)\n",
        "\n",
        "# Specify parameters to choose from\n",
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(50,50,50,50), (50,50,50), (50,50), (50,)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "}\n",
        "\n",
        "from scipy.stats import randint as sp_randint\n",
        "from scipy.stats import expon as sp_expon\n",
        "\n",
        "min_size, max_size = 5, 100\n",
        "parameter_space_distribution = {\n",
        "    'hidden_layer_sizes': [(sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
        "    'alpha': sp_expon(scale=.01),\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "    'learning_rate_init': sp_expon(scale=.001),\n",
        "}\n",
        "\n",
        "# Setup and run randomized search\n",
        "n_iter_search = 2\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=parameter_space_distribution, n_iter=n_iter_search, cv=3, verbose = 5)\n",
        "\n",
        "random_search.fit(trainX_scaled, np.int_(trainy))\n",
        "\n",
        "# Make predictions on test set\n",
        "y_true, y_pred = np.int_(testy) , random_search.predict(testX_scaled)\n",
        "print('Results on the test set:')\n",
        "print(r2_score(y_true, y_pred))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "[CV] solver=sgd, activation=tanh, hidden_layer_sizes=(45, 87), alpha=0.00231413506448271, learning_rate=adaptive, learning_rate_init=0.0008546381834146066 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=sgd, activation=tanh, hidden_layer_sizes=(45, 87), alpha=0.00231413506448271, learning_rate=adaptive, learning_rate_init=0.0008546381834146066, score=0.110366644029, total=   8.9s\n",
            "[CV] solver=sgd, activation=tanh, hidden_layer_sizes=(45, 87), alpha=0.00231413506448271, learning_rate=adaptive, learning_rate_init=0.0008546381834146066 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=sgd, activation=tanh, hidden_layer_sizes=(45, 87), alpha=0.00231413506448271, learning_rate=adaptive, learning_rate_init=0.0008546381834146066, score=0.177052653046, total=   5.7s\n",
            "[CV] solver=sgd, activation=tanh, hidden_layer_sizes=(45, 87), alpha=0.00231413506448271, learning_rate=adaptive, learning_rate_init=0.0008546381834146066 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   14.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=sgd, activation=tanh, hidden_layer_sizes=(45, 87), alpha=0.00231413506448271, learning_rate=adaptive, learning_rate_init=0.0008546381834146066, score=0.0828556511947, total=  26.1s\n",
            "[CV] solver=sgd, activation=tanh, hidden_layer_sizes=(72, 6, 47, 78), alpha=0.007543185359823325, learning_rate=constant, learning_rate_init=6.176346444157013e-05 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   40.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=sgd, activation=tanh, hidden_layer_sizes=(72, 6, 47, 78), alpha=0.007543185359823325, learning_rate=constant, learning_rate_init=6.176346444157013e-05, score=-0.00721595958877, total=  10.6s\n",
            "[CV] solver=sgd, activation=tanh, hidden_layer_sizes=(72, 6, 47, 78), alpha=0.007543185359823325, learning_rate=constant, learning_rate_init=6.176346444157013e-05 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   51.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=sgd, activation=tanh, hidden_layer_sizes=(72, 6, 47, 78), alpha=0.007543185359823325, learning_rate=constant, learning_rate_init=6.176346444157013e-05, score=0.147053166678, total=   8.0s\n",
            "[CV] solver=sgd, activation=tanh, hidden_layer_sizes=(72, 6, 47, 78), alpha=0.007543185359823325, learning_rate=constant, learning_rate_init=6.176346444157013e-05 \n",
            "[CV]  solver=sgd, activation=tanh, hidden_layer_sizes=(72, 6, 47, 78), alpha=0.007543185359823325, learning_rate=constant, learning_rate_init=6.176346444157013e-05, score=-0.0534148766011, total=   7.8s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results on the test set:\n",
            "-0.5445081042765052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZq4h8_mUmxr",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjkup0_nUlOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "2b33c3a9-8920-4cc9-d2e9-6796fe3a6209"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "trainy=trainy.astype('int')\n",
        "\n",
        "model = RandomForestRegressor(max_depth=10, random_state=0, verbose=2)\n",
        "model.fit(trainX_scaled, trainy)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "building tree 1 of 10\n",
            "building tree 2 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 3 of 10\n",
            "building tree 4 of 10\n",
            "building tree 5 of 10\n",
            "building tree 6 of 10\n",
            "building tree 7 of 10\n",
            "building tree 8 of 10\n",
            "building tree 9 of 10\n",
            "building tree 10 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
              "           oob_score=False, random_state=0, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZVbAYCjUuAD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c8ff7682-9699-4264-aa5c-a4563e03d9f9"
      },
      "source": [
        "print(\"R2 score for Random Forest:\")\n",
        "model.score(testX_scaled, testy)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2 score for Random Forest:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.061576470404669965"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J85_JQwZuHA",
        "colab_type": "text"
      },
      "source": [
        "### SASA-MAIN-CHAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUx2ctI0Z72-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global variable \n",
        "NUMBER_CHEMICAL_SHIFT_TYPE = 19\n",
        "\n",
        "def get_cs_all(cs_all, id = \"2KOC\"):\n",
        "  '''    \n",
        "    This function gets chemical shifts for a particular RNA. \n",
        "    Assumes each RNA has a unique id  \n",
        "  '''\n",
        "  return(cs_all[(cs_all.id == id)])\n",
        "\n",
        "def get_cs_residues(cs_i, resid, dummy = 0):\n",
        "  '''    \n",
        "    This function return an array containing the chemical shifts for a particular residues in an RNA.    \n",
        "  '''\n",
        "  cs_tmp = cs_i[(cs_i.resid == resid)].drop(['id', 'resid', 'resname', 'sasa-All-atoms',\t'sasa-Total-Side'\t, 'sasa-Main-Chain'\t,'sasa-Non-polar',\t'sasa-All-polar'], axis=1)\n",
        "  info_tmp = cs_i[(cs_i.resid == resid)]\n",
        "  if (cs_tmp.shape[0] != 1):\n",
        "     return(dummy*np.ones(shape=(1, NUMBER_CHEMICAL_SHIFT_TYPE)))\n",
        "  else:\n",
        "     return(cs_tmp.values)\n",
        "    \n",
        "def get_resnames(cs_i, resid, dummy = \"UNK\"):\n",
        "  '''    \n",
        "    This function returns the residue name for specified residue (resid)\n",
        "  '''\n",
        "  cs_tmp = cs_i[(cs_i.resid == resid)]  \n",
        "  if (cs_tmp.shape[0] != 1):\n",
        "     return(dummy)\n",
        "  else:\n",
        "     return(cs_tmp['resname'].values[0])\n",
        "\n",
        "def get_cs_features(cs_i, resid, neighbors=1):\n",
        "  '''    \n",
        "  This function chemical shifts and resnames for residue (resid) and its neighbors        \n",
        "\n",
        "  '''\n",
        "  cs = []\n",
        "  resnames = []\n",
        "  for i in range(resid-neighbors, resid+neighbors+1):\n",
        "    cs.append(get_cs_residues(cs_i, i))\n",
        "    resnames.append(get_resnames(cs_i, i))\n",
        "  return(resnames, np.array(cs))\n",
        "\n",
        "def get_columns_names(neighbors = 3, chemical_shift_types = 19):\n",
        "  '''\n",
        "    \n",
        "    Helper function that writes out the required column names\n",
        "    \n",
        "  '''\n",
        "\n",
        "  columns = ['id', 'resname', 'resid', 'sasa-Main-Chain']\n",
        "  for i in range(0, neighbors*chemical_shift_types):\n",
        "    columns.append(i)\n",
        "  return(columns)\n",
        "\n",
        "def write_out_resname(neighbors=1):\n",
        "  '''\n",
        "  \n",
        "    Helper function that writes out the column names associated resnames for a given residue and its neighbors\n",
        "    \n",
        "  '''  \n",
        "  colnames = []\n",
        "  for i in range(1-neighbors-1, neighbors+1):\n",
        "    if i < 0: \n",
        "      colnames.append('R%s'%i)\n",
        "    elif i > 0: \n",
        "      colnames.append('R+%s'%i)\n",
        "    else: \n",
        "      colnames.append('R')\n",
        "  return(colnames)    \n",
        "\n",
        "\n",
        "def get_cs_features_rna(cs, neighbors=1, retain = ['id', 'sasa-Main-Chain', 'resid']):\n",
        "  '''    \n",
        "    This function generates the complete required data frame an RNA    \n",
        "  '''\n",
        "  all_features = []\n",
        "  all_resnames = []\n",
        "  for resid in cs['resid'].unique():\n",
        "    resnames, features = get_cs_features(cs, resid, neighbors)\n",
        "    all_features.append(features.flatten())\n",
        "    all_resnames.append(resnames)\n",
        "\n",
        "  all_resnames = pd.DataFrame(all_resnames, columns = write_out_resname(neighbors))\n",
        "  all_features = pd.DataFrame(all_features)\n",
        "  info = pd.DataFrame(cs[retain].values, columns = retain)\n",
        "  return(pd.concat([info, all_resnames, all_features], axis=1))\n",
        "\n",
        "def get_cs_features_rna_all(cs, neighbors = 2):  \n",
        "  '''    \n",
        "    This [should] function generate a pandas dataframe containing training data for all RNAs\n",
        "    Each row in the data frame should contain the class and chemical shifts for given residue and neighbors in a given RNA.\n",
        "    Use the function above to write function\n",
        "  '''\n",
        "  \n",
        "  cs_new = pd.DataFrame()\n",
        "  for i in range(0,len(c.id.unique())):\n",
        "    csData = get_cs_features_rna(get_cs_all(cs, c.id.unique()[i]), neighbors)\n",
        "    cs_new = pd.concat([cs_new, csData], axis=0) \n",
        "  # End: your code\n",
        "  return(cs_new)\n",
        "\n",
        "def create_training_testing(cs, leave_out = '2KOC', target_name = 'sasa-Main-Chain', neighbors = 2, drop_names = ['id', 'sasa-Main-Chain', 'resid']):\n",
        "  '''    \n",
        "    This function creates a training and testing set using leave one out    \n",
        "  '''\n",
        "  \n",
        "  # drop extraneous data  \n",
        "  drop_names = drop_names + list(write_out_resname(neighbors))  \n",
        "  \n",
        "  # does not contain leave_out\n",
        "  train = cs[(cs.id != leave_out)]\n",
        "  trainX = train.drop(drop_names, axis=1)\n",
        "  trainy = train[target_name]\n",
        " \n",
        "  # only contains leave_out\n",
        "  test = cs[(cs.id == leave_out)]\n",
        "  testX = test.drop(drop_names, axis=1)\n",
        "  testy = test[target_name]\n",
        "  \n",
        "  # return training and testing data\n",
        "  return(trainX.values, trainy.values, testX.values, testy.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exX-pcYEaYPG",
        "colab_type": "code",
        "outputId": "4230d766-d2c6-448e-bf0e-4ef7ec1d023c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "NEIGHBORS = 1\n",
        "id = '1A60' #NEED TO FIGURE OUT WHY THE ID MUST MATCH THAT ABOVE/WHY CAN'T SELECT ANY ID\n",
        "\n",
        "cs_all = get_cs_features_rna_all(c, neighbors = NEIGHBORS)\n",
        "\n",
        "trainX, trainy, testX, testy = create_training_testing(cs_all, leave_out = id, neighbors = NEIGHBORS)\n",
        "print(\"[INFO]: created training and testing data structures\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO]: created training and testing data structures\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtgFrdPuahl-",
        "colab_type": "code",
        "outputId": "f8535c45-cb2e-4760-9a6f-6efa30518764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# setup scaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(trainX)\n",
        "\n",
        "# transform input\n",
        "trainX_scaled = scaler.transform(trainX)\n",
        "trainX_scaled = np.nan_to_num(trainX_scaled)\n",
        "testX_scaled = scaler.transform(testX)\n",
        "print(\"[INFO]: scaled the features\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO]: scaled the features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQkTbp20atzh",
        "colab_type": "code",
        "outputId": "313d072a-de65-4d8b-9e01-53be9a48113b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "\n",
        "# build a classifier\n",
        "clf = MLPRegressor(max_iter=1000)\n",
        "\n",
        "# Specify parameters to choose from\n",
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(50,50,50,50), (50,50,50), (50,50), (50,)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "}\n",
        "\n",
        "from scipy.stats import randint as sp_randint\n",
        "from scipy.stats import expon as sp_expon\n",
        "\n",
        "min_size, max_size = 5, 100\n",
        "parameter_space_distribution = {\n",
        "    'hidden_layer_sizes': [(sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
        "    'alpha': sp_expon(scale=.01),\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "    'learning_rate_init': sp_expon(scale=.001),\n",
        "}\n",
        "\n",
        "# Setup and run randomized search\n",
        "n_iter_search = 2\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=parameter_space_distribution, n_iter=n_iter_search, cv=3, verbose = 5)\n",
        "\n",
        "random_search.fit(trainX_scaled, np.int_(trainy))\n",
        "\n",
        "# Make predictions on test set\n",
        "y_true, y_pred = np.int_(testy) , random_search.predict(testX_scaled)\n",
        "print('Results on the test set:')\n",
        "print(r2_score(y_true, y_pred))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "[CV] solver=adam, activation=relu, hidden_layer_sizes=(98, 84, 88, 34), alpha=0.01243625321386744, learning_rate=constant, learning_rate_init=0.0006257809218790376 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=adam, activation=relu, hidden_layer_sizes=(98, 84, 88, 34), alpha=0.01243625321386744, learning_rate=constant, learning_rate_init=0.0006257809218790376, score=-0.0626949039685, total=  16.0s\n",
            "[CV] solver=adam, activation=relu, hidden_layer_sizes=(98, 84, 88, 34), alpha=0.01243625321386744, learning_rate=constant, learning_rate_init=0.0006257809218790376 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=adam, activation=relu, hidden_layer_sizes=(98, 84, 88, 34), alpha=0.01243625321386744, learning_rate=constant, learning_rate_init=0.0006257809218790376, score=0.00403662768157, total=  13.0s\n",
            "[CV] solver=adam, activation=relu, hidden_layer_sizes=(98, 84, 88, 34), alpha=0.01243625321386744, learning_rate=constant, learning_rate_init=0.0006257809218790376 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   29.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=adam, activation=relu, hidden_layer_sizes=(98, 84, 88, 34), alpha=0.01243625321386744, learning_rate=constant, learning_rate_init=0.0006257809218790376, score=-0.211383981672, total=  16.5s\n",
            "[CV] solver=lbfgs, activation=relu, hidden_layer_sizes=(80,), alpha=0.0046373589345600355, learning_rate=adaptive, learning_rate_init=0.0015804855194320373 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   45.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=lbfgs, activation=relu, hidden_layer_sizes=(80,), alpha=0.0046373589345600355, learning_rate=adaptive, learning_rate_init=0.0015804855194320373, score=-1.11767241102, total=   6.7s\n",
            "[CV] solver=lbfgs, activation=relu, hidden_layer_sizes=(80,), alpha=0.0046373589345600355, learning_rate=adaptive, learning_rate_init=0.0015804855194320373 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   52.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=lbfgs, activation=relu, hidden_layer_sizes=(80,), alpha=0.0046373589345600355, learning_rate=adaptive, learning_rate_init=0.0015804855194320373, score=-2.57569537384, total=   6.7s\n",
            "[CV] solver=lbfgs, activation=relu, hidden_layer_sizes=(80,), alpha=0.0046373589345600355, learning_rate=adaptive, learning_rate_init=0.0015804855194320373 \n",
            "[CV]  solver=lbfgs, activation=relu, hidden_layer_sizes=(80,), alpha=0.0046373589345600355, learning_rate=adaptive, learning_rate_init=0.0015804855194320373, score=-1.59535258779, total=   6.7s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results on the test set:\n",
            "-0.6255357226298663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcmk8S5eUyk5",
        "colab_type": "text"
      },
      "source": [
        "Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7SOs0eXUyEe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "83bd7e85-5bbe-4bcc-91be-0b1f71080c50"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "trainy=trainy.astype('int')\n",
        "\n",
        "model = RandomForestRegressor(max_depth=10, random_state=0, verbose=2)\n",
        "model.fit(trainX_scaled, trainy)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "building tree 1 of 10\n",
            "building tree 2 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 3 of 10\n",
            "building tree 4 of 10\n",
            "building tree 5 of 10\n",
            "building tree 6 of 10\n",
            "building tree 7 of 10\n",
            "building tree 8 of 10\n",
            "building tree 9 of 10\n",
            "building tree 10 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
              "           oob_score=False, random_state=0, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j7AFBhcUxG-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "28b95a67-511b-484b-8f9f-f8610344a953"
      },
      "source": [
        "print(\"R2 score for Random Forest:\")\n",
        "model.score(testX_scaled, testy)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2 score for Random Forest:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3219866870482875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haghaPDibtCo",
        "colab_type": "text"
      },
      "source": [
        "### SASA-NON-POLAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXDMfwU-bw4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global variable \n",
        "NUMBER_CHEMICAL_SHIFT_TYPE = 19\n",
        "\n",
        "def get_cs_all(cs_all, id = \"2KOC\"):\n",
        "  '''    \n",
        "    This function gets chemical shifts for a particular RNA. \n",
        "    Assumes each RNA has a unique id  \n",
        "  '''\n",
        "  return(cs_all[(cs_all.id == id)])\n",
        "\n",
        "def get_cs_residues(cs_i, resid, dummy = 0):\n",
        "  '''    \n",
        "    This function return an array containing the chemical shifts for a particular residues in an RNA.    \n",
        "  '''\n",
        "  cs_tmp = cs_i[(cs_i.resid == resid)].drop(['id', 'resid', 'resname', 'sasa-All-atoms',\t'sasa-Total-Side'\t, 'sasa-Main-Chain'\t,'sasa-Non-polar',\t'sasa-All-polar'], axis=1)\n",
        "  info_tmp = cs_i[(cs_i.resid == resid)]\n",
        "  if (cs_tmp.shape[0] != 1):\n",
        "     return(dummy*np.ones(shape=(1, NUMBER_CHEMICAL_SHIFT_TYPE)))\n",
        "  else:\n",
        "     return(cs_tmp.values)\n",
        "    \n",
        "def get_resnames(cs_i, resid, dummy = \"UNK\"):\n",
        "  '''    \n",
        "    This function returns the residue name for specified residue (resid)\n",
        "  '''\n",
        "  cs_tmp = cs_i[(cs_i.resid == resid)]  \n",
        "  if (cs_tmp.shape[0] != 1):\n",
        "     return(dummy)\n",
        "  else:\n",
        "     return(cs_tmp['resname'].values[0])\n",
        "\n",
        "def get_cs_features(cs_i, resid, neighbors=1):\n",
        "  '''    \n",
        "  This function chemical shifts and resnames for residue (resid) and its neighbors        \n",
        "\n",
        "  '''\n",
        "  cs = []\n",
        "  resnames = []\n",
        "  for i in range(resid-neighbors, resid+neighbors+1):\n",
        "    cs.append(get_cs_residues(cs_i, i))\n",
        "    resnames.append(get_resnames(cs_i, i))\n",
        "  return(resnames, np.array(cs))\n",
        "\n",
        "def get_columns_names(neighbors = 3, chemical_shift_types = 19):\n",
        "  '''\n",
        "    \n",
        "    Helper function that writes out the required column names\n",
        "    \n",
        "  '''\n",
        "\n",
        "  columns = ['id', 'resname', 'resid', 'sasa-Non-polar']\n",
        "  for i in range(0, neighbors*chemical_shift_types):\n",
        "    columns.append(i)\n",
        "  return(columns)\n",
        "\n",
        "def write_out_resname(neighbors=1):\n",
        "  '''\n",
        "  \n",
        "    Helper function that writes out the column names associated resnames for a given residue and its neighbors\n",
        "    \n",
        "  '''  \n",
        "  colnames = []\n",
        "  for i in range(1-neighbors-1, neighbors+1):\n",
        "    if i < 0: \n",
        "      colnames.append('R%s'%i)\n",
        "    elif i > 0: \n",
        "      colnames.append('R+%s'%i)\n",
        "    else: \n",
        "      colnames.append('R')\n",
        "  return(colnames)    \n",
        "\n",
        "\n",
        "def get_cs_features_rna(cs, neighbors=1, retain = ['id', 'sasa-Non-polar', 'resid']):\n",
        "  '''    \n",
        "    This function generates the complete required data frame an RNA    \n",
        "  '''\n",
        "  all_features = []\n",
        "  all_resnames = []\n",
        "  for resid in cs['resid'].unique():\n",
        "    resnames, features = get_cs_features(cs, resid, neighbors)\n",
        "    all_features.append(features.flatten())\n",
        "    all_resnames.append(resnames)\n",
        "\n",
        "  all_resnames = pd.DataFrame(all_resnames, columns = write_out_resname(neighbors))\n",
        "  all_features = pd.DataFrame(all_features)\n",
        "  info = pd.DataFrame(cs[retain].values, columns = retain)\n",
        "  return(pd.concat([info, all_resnames, all_features], axis=1))\n",
        "\n",
        "def get_cs_features_rna_all(cs, neighbors = 2):  \n",
        "  '''    \n",
        "    This [should] function generate a pandas dataframe containing training data for all RNAs\n",
        "    Each row in the data frame should contain the class and chemical shifts for given residue and neighbors in a given RNA.\n",
        "    Use the function above to write function\n",
        "  '''\n",
        "  \n",
        "  cs_new = pd.DataFrame()\n",
        "  for i in range(0,len(c.id.unique())):\n",
        "    csData = get_cs_features_rna(get_cs_all(cs, c.id.unique()[i]), neighbors)\n",
        "    cs_new = pd.concat([cs_new, csData], axis=0) \n",
        "  # End: your code\n",
        "  return(cs_new)\n",
        "\n",
        "def create_training_testing(cs, leave_out = '2KOC', target_name = 'sasa-Non-polar', neighbors = 2, drop_names = ['id', 'sasa-Non-polar', 'resid']):\n",
        "  '''    \n",
        "    This function creates a training and testing set using leave one out    \n",
        "  '''\n",
        "  \n",
        "  # drop extraneous data  \n",
        "  drop_names = drop_names + list(write_out_resname(neighbors))  \n",
        "  \n",
        "  # does not contain leave_out\n",
        "  train = cs[(cs.id != leave_out)]\n",
        "  trainX = train.drop(drop_names, axis=1)\n",
        "  trainy = train[target_name]\n",
        " \n",
        "  # only contains leave_out\n",
        "  test = cs[(cs.id == leave_out)]\n",
        "  testX = test.drop(drop_names, axis=1)\n",
        "  testy = test[target_name]\n",
        "  \n",
        "  # return training and testing data\n",
        "  return(trainX.values, trainy.values, testX.values, testy.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msrRmvjGcP4k",
        "colab_type": "code",
        "outputId": "14e2d22f-326e-4f09-b83b-2c93b0becdb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "NEIGHBORS = 1\n",
        "id = '1A60'\n",
        "\n",
        "cs_all = get_cs_features_rna_all(c, neighbors = NEIGHBORS)\n",
        "\n",
        "trainX, trainy, testX, testy = create_training_testing(cs_all, leave_out = id, neighbors = NEIGHBORS)\n",
        "print(\"[INFO]: created training and testing data structures\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO]: created training and testing data structures\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCKyCjFucatw",
        "colab_type": "code",
        "outputId": "e7386489-94ec-4d2c-b830-df341679cf8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# setup scaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(trainX)\n",
        "\n",
        "# transform input\n",
        "trainX_scaled = scaler.transform(trainX)\n",
        "trainX_scaled = np.nan_to_num(trainX_scaled)\n",
        "testX_scaled = scaler.transform(testX)\n",
        "print(\"[INFO]: scaled the features\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO]: scaled the features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2N89VkTcpWb",
        "colab_type": "code",
        "outputId": "32801e38-c59e-4770-80b3-87b8583ea13a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "# build a classifier\n",
        "clf = MLPRegressor(max_iter=1000)\n",
        "\n",
        "# Specify parameters to choose from\n",
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(50,50,50,50), (50,50,50), (50,50), (50,)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "}\n",
        "\n",
        "from scipy.stats import randint as sp_randint\n",
        "from scipy.stats import expon as sp_expon\n",
        "\n",
        "min_size, max_size = 5, 100\n",
        "parameter_space_distribution = {\n",
        "    'hidden_layer_sizes': [(sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
        "    'alpha': sp_expon(scale=.01),\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "    'learning_rate_init': sp_expon(scale=.001),\n",
        "}\n",
        "\n",
        "# Setup and run randomized search\n",
        "n_iter_search = 2\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=parameter_space_distribution, n_iter=n_iter_search, cv=3, verbose = 5)\n",
        "\n",
        "random_search.fit(trainX_scaled, np.int_(trainy))\n",
        "\n",
        "# Make predictions on test set\n",
        "y_true, y_pred = np.int_(testy) , random_search.predict(testX_scaled)\n",
        "print('Results on the test set:')\n",
        "print(r2_score(y_true, y_pred))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "[CV] solver=sgd, activation=tanh, hidden_layer_sizes=(76, 35), alpha=0.020327676759129328, learning_rate=adaptive, learning_rate_init=0.000991779069950693 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=sgd, activation=tanh, hidden_layer_sizes=(76, 35), alpha=0.020327676759129328, learning_rate=adaptive, learning_rate_init=0.000991779069950693, score=0.278333530949, total=   9.2s\n",
            "[CV] solver=sgd, activation=tanh, hidden_layer_sizes=(76, 35), alpha=0.020327676759129328, learning_rate=adaptive, learning_rate_init=0.000991779069950693 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=sgd, activation=tanh, hidden_layer_sizes=(76, 35), alpha=0.020327676759129328, learning_rate=adaptive, learning_rate_init=0.000991779069950693, score=0.101436772509, total=  13.4s\n",
            "[CV] solver=sgd, activation=tanh, hidden_layer_sizes=(76, 35), alpha=0.020327676759129328, learning_rate=adaptive, learning_rate_init=0.000991779069950693 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   22.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=sgd, activation=tanh, hidden_layer_sizes=(76, 35), alpha=0.020327676759129328, learning_rate=adaptive, learning_rate_init=0.000991779069950693, score=0.182905095143, total=  15.9s\n",
            "[CV] solver=sgd, activation=relu, hidden_layer_sizes=(76, 35), alpha=0.014649460553345369, learning_rate=adaptive, learning_rate_init=0.00037572641053988263 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   38.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=sgd, activation=relu, hidden_layer_sizes=(76, 35), alpha=0.014649460553345369, learning_rate=adaptive, learning_rate_init=0.00037572641053988263, score=0.327473546225, total=  10.1s\n",
            "[CV] solver=sgd, activation=relu, hidden_layer_sizes=(76, 35), alpha=0.014649460553345369, learning_rate=adaptive, learning_rate_init=0.00037572641053988263 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   48.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=sgd, activation=relu, hidden_layer_sizes=(76, 35), alpha=0.014649460553345369, learning_rate=adaptive, learning_rate_init=0.00037572641053988263, score=0.00741031563203, total=  12.1s\n",
            "[CV] solver=sgd, activation=relu, hidden_layer_sizes=(76, 35), alpha=0.014649460553345369, learning_rate=adaptive, learning_rate_init=0.00037572641053988263 \n",
            "[CV]  solver=sgd, activation=relu, hidden_layer_sizes=(76, 35), alpha=0.014649460553345369, learning_rate=adaptive, learning_rate_init=0.00037572641053988263, score=0.180963205594, total=   8.7s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results on the test set:\n",
            "-0.40919272580802435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VxXNnq7U9xH",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN9GnYMmU8fQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "86a4fdb3-4f6a-4e0a-b2b9-94de5ce549ff"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "trainy=trainy.astype('int')\n",
        "\n",
        "model = RandomForestRegressor(max_depth=10, random_state=0, verbose=2)\n",
        "model.fit(trainX_scaled, trainy)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "building tree 1 of 10\n",
            "building tree 2 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 3 of 10\n",
            "building tree 4 of 10\n",
            "building tree 5 of 10\n",
            "building tree 6 of 10\n",
            "building tree 7 of 10\n",
            "building tree 8 of 10\n",
            "building tree 9 of 10\n",
            "building tree 10 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
              "           oob_score=False, random_state=0, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMvJfbqkVA-x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "93d7e55c-8b91-4272-ba2b-b4b73b377134"
      },
      "source": [
        "print(\"R2 score for Random Forest:\")\n",
        "model.score(testX_scaled, testy)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2 score for Random Forest:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14450419702885586"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc63CTC9ee06",
        "colab_type": "text"
      },
      "source": [
        "### SASA-ALL-POLAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3OVCOUpeg7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global variable \n",
        "NUMBER_CHEMICAL_SHIFT_TYPE = 19\n",
        "\n",
        "def get_cs_all(cs_all, id = \"2KOC\"):\n",
        "  '''    \n",
        "    This function gets chemical shifts for a particular RNA. \n",
        "    Assumes each RNA has a unique id  \n",
        "  '''\n",
        "  return(cs_all[(cs_all.id == id)])\n",
        "\n",
        "def get_cs_residues(cs_i, resid, dummy = 0):\n",
        "  '''    \n",
        "    This function return an array containing the chemical shifts for a particular residues in an RNA.    \n",
        "  '''\n",
        "  cs_tmp = cs_i[(cs_i.resid == resid)].drop(['id', 'resid', 'resname', 'sasa-All-atoms',\t'sasa-Total-Side'\t, 'sasa-Main-Chain'\t,'sasa-Non-polar',\t'sasa-All-polar'], axis=1)\n",
        "  info_tmp = cs_i[(cs_i.resid == resid)]\n",
        "  if (cs_tmp.shape[0] != 1):\n",
        "     return(dummy*np.ones(shape=(1, NUMBER_CHEMICAL_SHIFT_TYPE)))\n",
        "  else:\n",
        "     return(cs_tmp.values)\n",
        "    \n",
        "def get_resnames(cs_i, resid, dummy = \"UNK\"):\n",
        "  '''    \n",
        "    This function returns the residue name for specified residue (resid)\n",
        "  '''\n",
        "  cs_tmp = cs_i[(cs_i.resid == resid)]  \n",
        "  if (cs_tmp.shape[0] != 1):\n",
        "     return(dummy)\n",
        "  else:\n",
        "     return(cs_tmp['resname'].values[0])\n",
        "\n",
        "def get_cs_features(cs_i, resid, neighbors=1):\n",
        "  '''    \n",
        "  This function chemical shifts and resnames for residue (resid) and its neighbors        \n",
        "\n",
        "  '''\n",
        "  cs = []\n",
        "  resnames = []\n",
        "  for i in range(resid-neighbors, resid+neighbors+1):\n",
        "    cs.append(get_cs_residues(cs_i, i))\n",
        "    resnames.append(get_resnames(cs_i, i))\n",
        "  return(resnames, np.array(cs))\n",
        "\n",
        "def get_columns_names(neighbors = 3, chemical_shift_types = 19):\n",
        "  '''\n",
        "    \n",
        "    Helper function that writes out the required column names\n",
        "    \n",
        "  '''\n",
        "\n",
        "  columns = ['id', 'resname', 'resid', 'sasa-All-polar']\n",
        "  for i in range(0, neighbors*chemical_shift_types):\n",
        "    columns.append(i)\n",
        "  return(columns)\n",
        "\n",
        "def write_out_resname(neighbors=1):\n",
        "  '''\n",
        "  \n",
        "    Helper function that writes out the column names associated resnames for a given residue and its neighbors\n",
        "    \n",
        "  '''  \n",
        "  colnames = []\n",
        "  for i in range(1-neighbors-1, neighbors+1):\n",
        "    if i < 0: \n",
        "      colnames.append('R%s'%i)\n",
        "    elif i > 0: \n",
        "      colnames.append('R+%s'%i)\n",
        "    else: \n",
        "      colnames.append('R')\n",
        "  return(colnames)    \n",
        "\n",
        "\n",
        "def get_cs_features_rna(cs, neighbors=1, retain = ['id', 'sasa-All-polar', 'resid']):\n",
        "  '''    \n",
        "    This function generates the complete required data frame an RNA    \n",
        "  '''\n",
        "  all_features = []\n",
        "  all_resnames = []\n",
        "  for resid in cs['resid'].unique():\n",
        "    resnames, features = get_cs_features(cs, resid, neighbors)\n",
        "    all_features.append(features.flatten())\n",
        "    all_resnames.append(resnames)\n",
        "\n",
        "  all_resnames = pd.DataFrame(all_resnames, columns = write_out_resname(neighbors))\n",
        "  all_features = pd.DataFrame(all_features)\n",
        "  info = pd.DataFrame(cs[retain].values, columns = retain)\n",
        "  return(pd.concat([info, all_resnames, all_features], axis=1))\n",
        "\n",
        "def get_cs_features_rna_all(cs, neighbors = 2):  \n",
        "  '''    \n",
        "    This [should] function generate a pandas dataframe containing training data for all RNAs\n",
        "    Each row in the data frame should contain the class and chemical shifts for given residue and neighbors in a given RNA.\n",
        "    Use the function above to write function\n",
        "  '''\n",
        "  \n",
        "  cs_new = pd.DataFrame()\n",
        "  for i in range(0,len(c.id.unique())):\n",
        "    csData = get_cs_features_rna(get_cs_all(cs, c.id.unique()[i]), neighbors)\n",
        "    cs_new = pd.concat([cs_new, csData], axis=0) \n",
        "  # End: your code\n",
        "  return(cs_new)\n",
        "\n",
        "def create_training_testing(cs, leave_out = '2KOC', target_name = 'sasa-All-polar', neighbors = 2, drop_names = ['id', 'sasa-All-polar', 'resid']):\n",
        "  '''    \n",
        "    This function creates a training and testing set using leave one out    \n",
        "  '''\n",
        "  \n",
        "  # drop extraneous data  \n",
        "  drop_names = drop_names + list(write_out_resname(neighbors))  \n",
        "  \n",
        "  # does not contain leave_out\n",
        "  train = cs[(cs.id != leave_out)]\n",
        "  trainX = train.drop(drop_names, axis=1)\n",
        "  trainy = train[target_name]\n",
        " \n",
        "  # only contains leave_out\n",
        "  test = cs[(cs.id == leave_out)]\n",
        "  testX = test.drop(drop_names, axis=1)\n",
        "  testy = test[target_name]\n",
        "  \n",
        "  # return training and testing data\n",
        "  return(trainX.values, trainy.values, testX.values, testy.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmENBQVSf0PQ",
        "colab_type": "code",
        "outputId": "46366330-54fc-450f-97a1-54ca4075115c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "NEIGHBORS = 1\n",
        "id = '1A60'\n",
        "\n",
        "cs_all = get_cs_features_rna_all(c, neighbors = NEIGHBORS)\n",
        "\n",
        "trainX, trainy, testX, testy = create_training_testing(cs_all, leave_out = id, neighbors = NEIGHBORS)\n",
        "print(\"[INFO]: created training and testing data structures\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO]: created training and testing data structures\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbVdn5hTf1KD",
        "colab_type": "code",
        "outputId": "2fadb959-cb00-4da6-c6de-9b94d5016a7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# setup scaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(trainX)\n",
        "\n",
        "# transform input\n",
        "trainX_scaled = scaler.transform(trainX)\n",
        "trainX_scaled = np.nan_to_num(trainX_scaled)\n",
        "testX_scaled = scaler.transform(testX)\n",
        "print(\"[INFO]: scaled the features\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO]: scaled the features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLf9G2sgf74H",
        "colab_type": "code",
        "outputId": "864cbb10-dddf-4292-bf5b-975af89d1121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "# build a classifier\n",
        "clf = MLPRegressor(max_iter=1000)\n",
        "\n",
        "# Specify parameters to choose from\n",
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(50,50,50,50), (50,50,50), (50,50), (50,)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "}\n",
        "\n",
        "from scipy.stats import randint as sp_randint\n",
        "from scipy.stats import expon as sp_expon\n",
        "\n",
        "min_size, max_size = 5, 100\n",
        "parameter_space_distribution = {\n",
        "    'hidden_layer_sizes': [(sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),sp_randint.rvs(min_size, max_size)), (sp_randint.rvs(min_size, max_size),)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
        "    'alpha': sp_expon(scale=.01),\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "    'learning_rate_init': sp_expon(scale=.001),\n",
        "}\n",
        "\n",
        "# Setup and run randomized search\n",
        "n_iter_search = 2\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=parameter_space_distribution, n_iter=n_iter_search, cv=3, verbose = 5)\n",
        "\n",
        "random_search.fit(trainX_scaled, np.int_(trainy))\n",
        "\n",
        "# Make predictions on test set\n",
        "y_true, y_pred = np.int_(testy) , random_search.predict(testX_scaled)\n",
        "print('Results on the test set:')\n",
        "print(r2_score(y_true, y_pred))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "[CV] solver=adam, activation=tanh, hidden_layer_sizes=(49,), alpha=0.019108088305276313, learning_rate=adaptive, learning_rate_init=3.877211058234038e-05 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=adam, activation=tanh, hidden_layer_sizes=(49,), alpha=0.019108088305276313, learning_rate=adaptive, learning_rate_init=3.877211058234038e-05, score=-16.5008273697, total=  12.6s\n",
            "[CV] solver=adam, activation=tanh, hidden_layer_sizes=(49,), alpha=0.019108088305276313, learning_rate=adaptive, learning_rate_init=3.877211058234038e-05 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=adam, activation=tanh, hidden_layer_sizes=(49,), alpha=0.019108088305276313, learning_rate=adaptive, learning_rate_init=3.877211058234038e-05, score=-13.2584305328, total=  12.6s\n",
            "[CV] solver=adam, activation=tanh, hidden_layer_sizes=(49,), alpha=0.019108088305276313, learning_rate=adaptive, learning_rate_init=3.877211058234038e-05 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   25.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=adam, activation=tanh, hidden_layer_sizes=(49,), alpha=0.019108088305276313, learning_rate=adaptive, learning_rate_init=3.877211058234038e-05, score=-20.9654908585, total=  12.6s\n",
            "[CV] solver=adam, activation=relu, hidden_layer_sizes=(58, 35, 77), alpha=0.006631566350992895, learning_rate=constant, learning_rate_init=0.0006865467290116567 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   37.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=adam, activation=relu, hidden_layer_sizes=(58, 35, 77), alpha=0.006631566350992895, learning_rate=constant, learning_rate_init=0.0006865467290116567, score=-0.0119797274951, total=  10.1s\n",
            "[CV] solver=adam, activation=relu, hidden_layer_sizes=(58, 35, 77), alpha=0.006631566350992895, learning_rate=constant, learning_rate_init=0.0006865467290116567 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   47.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  solver=adam, activation=relu, hidden_layer_sizes=(58, 35, 77), alpha=0.006631566350992895, learning_rate=constant, learning_rate_init=0.0006865467290116567, score=0.112914450955, total=  12.5s\n",
            "[CV] solver=adam, activation=relu, hidden_layer_sizes=(58, 35, 77), alpha=0.006631566350992895, learning_rate=constant, learning_rate_init=0.0006865467290116567 \n",
            "[CV]  solver=adam, activation=relu, hidden_layer_sizes=(58, 35, 77), alpha=0.006631566350992895, learning_rate=constant, learning_rate_init=0.0006865467290116567, score=-0.0999091658404, total=  10.8s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results on the test set:\n",
            "-0.2671503495553025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDsIytUMVHoC",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi6OuELgVHTx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "5f2fe67e-f2bc-40aa-e3cf-2651140eb40b"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "trainy=trainy.astype('int')\n",
        "\n",
        "model = RandomForestRegressor(max_depth=10, random_state=0, verbose=2)\n",
        "model.fit(trainX_scaled, trainy)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "building tree 1 of 10\n",
            "building tree 2 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building tree 3 of 10\n",
            "building tree 4 of 10\n",
            "building tree 5 of 10\n",
            "building tree 6 of 10\n",
            "building tree 7 of 10\n",
            "building tree 8 of 10\n",
            "building tree 9 of 10\n",
            "building tree 10 of 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
              "           oob_score=False, random_state=0, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oILIQKfZVG0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f545bb91-a3b1-4e24-e586-6b2da2a8eaf2"
      },
      "source": [
        "print(\"R2 score for Random Forest:\")\n",
        "model.score(testX_scaled, testy)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2 score for Random Forest:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.04256304319648696"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    }
  ]
}